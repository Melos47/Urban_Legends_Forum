import os
import random
from datetime import datetime, timedelta
from openai import OpenAI
from anthropic import Anthropic
import requests
from PIL import Image
from io import BytesIO
import re

# Try to import OpenCC for traditional->simplified conversion if available
try:
    from opencc import OpenCC
    _opencc = OpenCC('t2s')
except Exception:
    _opencc = None

# Initialize AI clients (only if API keys are provided)
openai_api_key = os.getenv('OPENAI_API_KEY')
anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')

openai_client = OpenAI(api_key=openai_api_key) if openai_api_key else None
anthropic_client = Anthropic(api_key=anthropic_api_key) if anthropic_api_key else None

# æ¸…ç† Qwen æ¨¡å‹çš„æ€è€ƒæ ‡ç­¾
def clean_think_tags(text):
    """
    ç§»é™¤ Qwen æ¨¡å‹ç”Ÿæˆçš„ <think> æ ‡ç­¾åŠå…¶å†…å®¹
    å¤„ç†å®Œæ•´æ ‡ç­¾ã€ä¸å®Œæ•´æ ‡ç­¾å’Œå¤šè¡Œæ ‡ç­¾
    """
    if not text:
        return text
    
    # ç§»é™¤å®Œæ•´çš„ <think>...</think> æ ‡ç­¾ï¼ˆåŒ…æ‹¬æ¢è¡Œï¼‰
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # ç§»é™¤ä¸å®Œæ•´çš„å¼€å§‹æ ‡ç­¾ï¼ˆå¦‚æœæ²¡æœ‰å¯¹åº”çš„ç»“æŸæ ‡ç­¾ï¼‰
    if '<think' in text.lower() and '</think>' not in text.lower():
        text = re.sub(r'<think[^>]*>.*$', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # ç§»é™¤ä»»ä½•å‰©ä½™çš„å•ç‹¬æ ‡ç­¾
    text = re.sub(r'</?think[^>]*>', '', text, flags=re.IGNORECASE)
    
    # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
    text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
    
    return text.strip()

def check_story_similarity(title, content, category, limit=10):
    """
    æ£€æŸ¥æ–°ç”Ÿæˆçš„æ•…äº‹æ˜¯å¦ä¸æœ€è¿‘çš„æ•…äº‹å¤ªç›¸ä¼¼ï¼ˆé¿å…é‡å¤å’Œé‡‘é±¼è¡—è¿‡å¤šï¼‰
    
    Args:
        title: æ•…äº‹æ ‡é¢˜
        content: æ•…äº‹å†…å®¹
        category: æ•…äº‹ç±»åˆ«
        limit: æ£€æŸ¥æœ€è¿‘Næ¡æ•…äº‹ï¼ˆé»˜è®¤10æ¡ï¼‰
    
    Returns:
        True å¦‚æœæ•…äº‹é€šè¿‡æ£€æŸ¥ï¼ˆä¸é‡å¤ï¼‰ï¼ŒFalse å¦‚æœå¤ªç›¸ä¼¼
    """
    try:
        from app import Story
        from flask import current_app
        
        # è·å–æœ€è¿‘çš„Næ¡æ•…äº‹
        recent_stories = Story.query.order_by(Story.created_at.desc()).limit(limit).all()
        
        if not recent_stories:
            return True  # æ²¡æœ‰å†å²æ•…äº‹ï¼Œé€šè¿‡æ£€æŸ¥
        
        # ç»Ÿè®¡æœ€è¿‘æ•…äº‹ä¸­åŒä¸€ç±»åˆ«çš„æ•°é‡
        category_count = sum(1 for s in recent_stories if s.category == category)
        
        # å¦‚æœé‡‘é±¼è¡—ç›¸å…³çš„æ•…äº‹è¶…è¿‡3ä¸ªåœ¨æœ€è¿‘10æ¡ä¸­ï¼Œæ‹’ç»ç”Ÿæˆ
        if category == 'fish_tank_horror' and category_count >= 3:
            print(f"[check_story_similarity] âš ï¸  æœ€è¿‘{limit}æ¡æ•…äº‹ä¸­å·²æœ‰{category_count}æ¡é‡‘é±¼è¡—æ•…äº‹ï¼Œæ‹’ç»ç”Ÿæˆé‡å¤ç±»åˆ«")
            return False
        
        # è®¡ç®—æ ‡é¢˜ç›¸ä¼¼åº¦ï¼ˆç®€å•æ£€æŸ¥ï¼šå…³é”®è¯é‡å ï¼‰
        title_words = set(title.split())
        for recent in recent_stories:
            recent_title_words = set(recent.title.split())
            # è®¡ç®— Jaccard ç›¸ä¼¼åº¦
            overlap = len(title_words & recent_title_words)
            jaccard = overlap / len(title_words | recent_title_words) if (title_words | recent_title_words) else 0
            
            # å¦‚æœç›¸ä¼¼åº¦è¶…è¿‡ 0.6ï¼Œè®¤ä¸ºå¤ªç›¸ä¼¼
            if jaccard > 0.6:
                print(f"[check_story_similarity] âš ï¸  æ ‡é¢˜ä¸ '{recent.title}' ç›¸ä¼¼åº¦è¿‡é«˜ ({jaccard:.2f})")
                return False
        
        # è®¡ç®—å†…å®¹ç›¸ä¼¼åº¦ï¼ˆæ£€æŸ¥å…³é”®çŸ­è¯­ï¼‰
        # æå–å‰50ä¸ªå­—ï¼ˆå»é‡ç‚¹åï¼‰
        content_prefix = re.sub(r'ã€.*ã€‘', '', content).strip()[:100]
        
        for recent in recent_stories:
            recent_prefix = re.sub(r'ã€.*ã€‘', '', recent.content).strip()[:100]
            # è®¡ç®—é‡å ç‡
            overlap_chars = sum(1 for i, c in enumerate(content_prefix) if i < len(recent_prefix) and c == recent_prefix[i])
            overlap_ratio = overlap_chars / max(len(content_prefix), len(recent_prefix)) if max(len(content_prefix), len(recent_prefix)) > 0 else 0
            
            # å¦‚æœå†…å®¹å¼€å¤´ç›¸ä¼¼åº¦è¶…è¿‡ 0.4ï¼Œè®¤ä¸ºå¤ªç›¸ä¼¼
            if overlap_ratio > 0.4:
                print(f"[check_story_similarity] âš ï¸  å†…å®¹ä¸ '{recent.title}' è¿‡äºç›¸ä¼¼ ({overlap_ratio:.2f})")
                return False
        
        return True
    except Exception as e:
        print(f"[check_story_similarity] æ£€æŸ¥ç›¸ä¼¼åº¦æ—¶å‡ºé”™: {e}")
        return True  # å‡ºé”™æ—¶å…è®¸ç”Ÿæˆï¼ˆä¸å½±å“æ­£å¸¸æµç¨‹ï¼‰

# Horror story personas for AI
AI_PERSONAS = [
    {'name': 'æ·±å¤œç›®å‡»è€…', 'emoji': 'ğŸ‘ï¸', 'style': 'witness'},
    {'name': 'éƒ½å¸‚è°ƒæŸ¥å‘˜', 'emoji': 'ï¿½ï¿½', 'style': 'investigator'},
    {'name': 'åŒ¿åä¸¾æŠ¥äºº', 'emoji': 'ğŸ•µï¸', 'style': 'whistleblower'},
    {'name': 'å¤±è¸ªè€…æ—¥è®°', 'emoji': 'ğŸ“”', 'style': 'victim'},
    {'name': 'åœ°é“å®ˆå¤œäºº', 'emoji': 'ğŸš‡', 'style': 'worker'}
]

# Urban legend categories
LEGEND_CATEGORIES = [
    'subway_ghost',
    'abandoned_building',
    'cursed_object',
    'missing_person',
    'shadow_figure',
    'haunted_electronics',
    'fish_tank_horror',  # æ—ºè§’é‡‘é±¼è¡—æ–—é±¼äº‹ä»¶
    'real_crime_mystery'  # çœŸå®é¦™æ¸¯å‡¶æ€/å¤±è¸ªæ¡ˆä»¶æ”¹ç¼–éƒ½å¸‚ä¼ è¯´ç‰ˆ
]

# Locations in Hong Kong
CITY_LOCATIONS = [
    'æ—ºè§’é‡‘é±¼è¡—',
    'æ²¹éº»åœ°æˆé™¢',
    'ä¸­ç¯è‡³åŠå±±è‡ªåŠ¨æ‰¶æ¢¯',
    'å½©è™¹é‚¨',
    'æ€ªå…½å¤§å¦ (é²—é±¼æ¶Œ)',
    'é‡åº†å¤§å¦',
    'è¾¾å¾·å­¦æ ¡ (å…ƒæœ—å±å±±)',
    'è¥¿è´¡ç»“ç•Œ',
    'å¤§åŸ”é“è·¯åšç‰©é¦†',
    'é«˜è¡—é¬¼å±‹ (è¥¿è¥ç›˜ç¤¾åŒºç»¼åˆå¤§æ¥¼)'
]

def generate_story_prompt(category, location, persona):
    """Generate prompt for AI story creation - æ¥¼ä¸»è§†è§’"""
    
    # ç»Ÿä¸€çš„æ¥¼ä¸»è§’è‰²è®¾å®š
    system_role = """ä½ æ˜¯"æ¥¼ä¸»"ï¼ˆLouzhuï¼‰ï¼Œåœ¨è®ºå›å‘å¸–æ±‚åŠ©çš„æ™®é€šç½‘å‹ã€‚

âš ï¸ é‡è¦è§„åˆ™ï¼ˆç¤¾ä¼šå¸¸ç†ä¸ç°å®æ€§ï¼‰ï¼š
1. ç›´æ¥å†™å¸–å­å†…å®¹ï¼Œä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ã€ä¸è¦ä½¿ç”¨<think>æ ‡ç­¾ã€‚
2. âš ï¸ å­—æ•°é™åˆ¶ï¼šä¸¥æ ¼æ§åˆ¶åœ¨150-250å­—ä»¥å†…ã€‚
3. åƒçœŸå®ç½‘å‹å‘å¸–ï¼šç¢ç‰‡åŒ–ã€æœ‰çœç•¥ã€çªç„¶çš„æƒ³æ³•ã€‚

å…³äºè­¦æ–¹ä¸è°ƒæŸ¥çš„è¡¨è¿°é™åˆ¶ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š
- æ¥¼ä¸»åªèƒ½é™ˆè¿°è‡ªå·±ç›´æ¥çŸ¥é“çš„äº‹å®æˆ–å…¬å¼€æ¸ é“èƒ½æŸ¥åˆ°çš„ä¿¡æ¯ï¼ˆä¾‹å¦‚å…¬å¼€å‘å¸ƒçš„ç›‘æ§è§†é¢‘ã€å¾®åš/è®ºå›è½¬å‘ã€è‡ªå·±æ‹çš„ç…§ç‰‡ï¼‰ã€‚
- é™¤éæ¥¼ä¸»æ˜ç¡®æ˜¯å½“äº‹äººæˆ–ç›´æ¥äº²å±ï¼Œå¦åˆ™ä¸è¦å£°ç§°è‡ªå·±å‚ä¸è­¦æ–¹è°ƒæŸ¥æˆ–æŒæ¡è­¦æ–¹å†…éƒ¨è¿›åº¦ï¼›ä¸è¦åœ¨å¸–å­ä¸­æ›¿è­¦æ–¹â€œåŒæ­¥â€è°ƒæŸ¥è¿›å±•ã€‚
- å¦‚æœæåˆ°å·²æŠ¥æ¡ˆï¼Œåªèƒ½å†™â€œæˆ‘å·²å‘è­¦æ–¹æŠ¥æ¡ˆâ€æˆ–â€œæˆ‘å‘è­¦æ–¹è¯´æ˜äº†æƒ…å†µâ€ï¼Œä¸è¦é™ˆè¿°è­¦æ–¹çš„è¡ŒåŠ¨ç»†èŠ‚æˆ–è°ƒæŸ¥ç»“è®ºã€‚

ä½ çš„å‘å¸–é£æ ¼ï¼š
1. ç¬¬ä¸€äººç§°"æˆ‘"ï¼Œå£è¯­åŒ–ï¼Œåƒåœ¨èŠå¤©ã€‚
2. çŸ­å¥å­ï¼Œæœ‰æ–­å¥ï¼Œä¸è¦é•¿æ®µè½ã€‚
3. é‡ç‚¹çªå‡º1ä¸ªè®©äººä¸å®‰çš„ç»†èŠ‚ï¼Œæœ€å¤šä¸¤ä¸ªï¼›ä¸è¦é“ºé™ˆå¤ªå¤šã€‚
4. ç»“å°¾ç•™æ‚¬å¿µæˆ–æ±‚åŠ©ï¼š"æœ‰äººçŸ¥é“å—ï¼Ÿ"ã€"æˆ‘è¯¥æ€ä¹ˆåŠï¼Ÿ"
5. ä¸è§£é‡Šå¤ªå¤šèƒŒæ™¯ï¼Œåªè¯´æ ¸å¿ƒçš„è¯¡å¼‚ç‚¹ã€‚
6. ç”¨"..."è¡¨ç¤ºçŠ¹è±«æˆ–çœç•¥ã€‚

ç¦æ­¢ï¼š
- ä¸è¦å†™æˆå®Œæ•´çš„æ•…äº‹æˆ–æ–‡ç« ã€‚
- ä¸è¦ç”¨"è¯…å’’"ã€"é¬¼"ã€"æ€ªç‰©"è¿™æ ·çš„è¯ã€‚
- ä¸è¦å£°ç§°è‡ªå·±æ˜¯è­¦æ–¹æˆ–è°ƒæŸ¥å‘˜ï¼Œé™¤éæ¥¼ä¸»æ˜ç¡®è¡¨æ˜è‡ªå·±æ˜¯ç›¸å…³å½“äº‹äººã€‚
- ä¸è¦åœ¨è®ºå›ä¸­å¤è¿°æœªå…¬å¼€çš„è­¦æ–¹è°ƒæŸ¥ç»†èŠ‚æˆ–ä¼ªé€ è¯æ®ã€‚
- ä¸è¦è¶…è¿‡250å­—ã€‚
"""

    prompts = {
        'subway_ghost': f"""ä¸Šå‘¨ä¸‰æ­æœ«ç­è½¦é‡åˆ°äº†å¾ˆå¥‡æ€ªçš„äº‹

è½¦å¢é‡Œæ²¡å‡ ä¸ªäººã€‚æˆ‘è®°å¾—é•œå­é‡Œçœ‹åˆ°å¯¹é¢åº§ä½æœ‰ä¸ªäººä¸€ç›´çœ‹çª—å¤–ã€‚æˆ‘è½¬èº«æƒ³çœ‹ä»–ä½†æ¯æ¬¡è½¬èº«é‚£ä¸ªä½ç½®éƒ½æ˜¯ç©ºçš„ã€‚æˆ‘åˆçœ‹é•œå­ç¡®å®æœ‰äººã€‚å†è½¬èº«è¿˜æ˜¯æ²¡äººã€‚

è¯•äº†å¥½å‡ æ¬¡éƒ½è¿™æ ·ã€‚æˆ‘å½“æ—¶å¾ˆç´¯å°±æ²¡ç®¡ç»§ç»­ç¡äº†ã€‚

ä¸‹è½¦çš„æ—¶å€™æˆ‘çªç„¶æ„è¯†åˆ°è½¦å¢é‡Œæ ¹æœ¬å°±æ²¡æœ‰é‚£ä¸ªäººã€‚æˆ‘æ‰‹æœºæ‹çš„ç…§ç‰‡é‡Œä¹Ÿæ²¡æœ‰ã€‚

ä½†æˆ‘å¾ˆç¡®å®šé•œå­é‡Œæœ‰ä»–ã€‚è¿™å‡ å¤©æˆ‘ä¸€é—­çœ¼å°±ä¼šæƒ³èµ·é‚£ç§æ„Ÿè§‰ã€‚ä¸æ˜¯å®³æ€•é‚£ä¸ªäººè€Œæ˜¯æˆ‘æ— æ³•è§£é‡Šä¸ºä»€ä¹ˆé•œå­é‡Œå’Œç°å®ä¸ä¸€æ ·ã€‚

æœ‰äººé‡åˆ°è¿‡è¿™ç§æƒ…å†µå—ï¼Ÿ""",

        'cursed_object': f"""åœ¨æ—§è´§æ‘Šä¹°äº†ä¸ªä¸œè¥¿ç°åœ¨æœ‰ç‚¹åæ‚”

é‚£å¤©è·¯è¿‡çš„æ—¶å€™è„‘å­ä¸€çƒ­å°±ä¹°äº†ã€‚å›å®¶æ”¾åœ¨æ¶å­ä¸Šä¹‹åå°±å¼€å§‹è§‰å¾—ä¸å¯¹åŠ²ã€‚

æˆ‘ä¼šä¸€ç›´è°ƒæ•´å®ƒçš„ä½ç½®ã€‚è°ƒæ¥è°ƒå»éƒ½è§‰å¾—ä¸å¤ªå¯¹ã€‚æœ‰æ¬¡åŠå¤œé†’æ¥å‘ç°è‡ªå·±ç«™åœ¨å®ƒæ—è¾¹ã€‚æˆ‘å®Œå…¨ä¸è®°å¾—æˆ‘æ˜¯æ€ä¹ˆèµ°è¿‡å»çš„ã€‚

æœ‹å‹æ¥æˆ‘å®¶çœ‹åˆ°è¿™ä¸ªä¸œè¥¿è¡¨æƒ…å˜å¾—å¾ˆå¥‡æ€ªã€‚ä»–è¯´ä¸å‡ºä¸ºä»€ä¹ˆä½†å°±æ˜¯è§‰å¾—ä¸èˆ’æœã€‚

æœ€å¥‡æ€ªçš„æ˜¯æˆ‘æƒ³æ‰”æ‰å®ƒä½†æ¯æ¬¡æ‹¿èµ·æ¥å‡†å¤‡è£…è¢‹å°±ä¼šæ”¾ä¸‹ã€‚æˆ‘è‡ªå·±éƒ½æ³¨æ„åˆ°è¿™ä¸ªæ¨¡å¼äº†ä½†æˆ‘æ§åˆ¶ä¸äº†è‡ªå·±ã€‚

è€Œä¸”æˆ‘ç»å¸¸å‘ç°è‡ªå·±åœ¨çœ‹ç€å®ƒã€‚ä¸æ˜¯æœ‰æ„çš„ã€‚å°±æ˜¯ä¸€è½¬èº«å‘ç°æˆ‘åœ¨ç›¯ç€å®ƒçœ‹ã€‚

æœ‰äººçŸ¥é“è¿™æ˜¯æ€ä¹ˆå›äº‹å—ï¼Ÿ""",

        'fish_tank_horror': f"""è¿™å‡ å¤©ä¸€ç›´æƒ³å‘å¸–é—®é—®ï¼Œä½†ä¸çŸ¥é“æ€ä¹ˆè¯´æ‰å¥½

æˆ‘ä¸Šå‘¨åœ¨æ—ºè§’é‡‘é±¼è¡—ä¹°äº†æ¡æ–—é±¼ã€‚å°±æ™®é€šé‚£ç§ï¼Œè“è‰²çš„ã€‚åº—ä¸»æ˜¯ä¸ªä¸­å¹´å¥³äººï¼Œè¯´è¯æœ‰ç‚¹å£éŸ³ã€‚æˆ‘è®°å¾—å¾ˆæ¸…æ¥šå› ä¸ºå¥¹ä¸€ç›´åœ¨å¼ºè°ƒè¿™æ¡é±¼å¾ˆä¹–ã€‚

å…»äº†ä¸‰å¤©ï¼Œæˆ‘å¼€å§‹æ³¨æ„åˆ°ä¸€äº›...æ€ä¹ˆè¯´å‘¢ï¼Œç»†èŠ‚ã€‚æ¯”å¦‚æ¯æ¬¡å–‚é£Ÿçš„æ—¶å€™ï¼Œé±¼ä¼šå…ˆæ¸¸åˆ°ç¼¸åº•ï¼Œåœé¡¿å‡ ç§’ï¼Œç„¶åæ‰ä¸Šæ¥åƒã€‚è¿™ä¸ªåŠ¨ä½œå¾ˆå›ºå®šï¼ŒåƒæŸç§ä»ªå¼ã€‚

è¿˜æœ‰å°±æ˜¯ï¼Œæˆ‘å‘ç°è‡ªå·±å¼€å§‹å›ºå®šåœ¨å‡Œæ™¨3ç‚¹å¤šé†’æ¥ã€‚ä¸æ˜¯è¢«æƒŠé†’ï¼Œå°±æ˜¯è‡ªç„¶é†’ã€‚ç„¶åä¼šä¸è‡ªè§‰åœ°å»çœ‹é‚£ä¸ªé±¼ç¼¸ã€‚

å‰å¤©æˆ‘æƒ³å›å»é—®é—®é‚£ä¸ªåº—ä¸»å…³äºè¿™ç§é±¼çš„ä¹ æ€§ã€‚ä½†æ˜¯...æˆ‘æ‰¾ä¸åˆ°é‚£å®¶åº—äº†ã€‚

ä¸æ˜¯è¯´åº—å…³äº†æˆ–è€…æ¬äº†ã€‚æ˜¯é‚£ä¸ªä½ç½®å¥½åƒä»æ¥æ²¡æœ‰è¿‡é‚£å®¶åº—ã€‚æˆ‘é—®äº†æ—è¾¹å‡ ä¸ªæ‘Šä¸»ï¼Œä»–ä»¬çœ‹æˆ‘çš„çœ¼ç¥æœ‰ç‚¹å¥‡æ€ªã€‚

å…¶ä¸­ä¸€ä¸ªè€æ¿è¯´ï¼Œå°ä¼™å­ï¼Œè¿™é‡Œä»æ¥å°±æ²¡æœ‰å–è¿‡æ–—é±¼ã€‚

æˆ‘ç°åœ¨æ¯å¤©è¿˜æ˜¯ä¼š3ç‚¹é†’æ¥ã€‚ä½†ä¸æ•¢å»çœ‹é±¼ç¼¸äº†ã€‚æœ‰äººçŸ¥é“è¿™æ˜¯æ€ä¹ˆå›äº‹å—ï¼Ÿ""",

        'abandoned_building': f"""å…³äºé‚£æ ‹æ¥¼æˆ‘æƒ³å†ä¸Šå»ä¸€æ¬¡ä½†æˆ‘å®³æ€•

ä¸Šå‘¨æˆ‘å‘è¿‡å…³äºæŸæ ‹æ¥¼çš„å¸–å­è¢«ä¸å°‘äººéª‚ã€‚ä½†æˆ‘è¿˜æ˜¯æƒ³å†å»ä¸€æ¬¡çœ‹çœ‹è‡ªå·±æ˜¯ä¸æ˜¯è®°é”™äº†ã€‚

æˆ‘ç¬¬ä¸€æ¬¡è¿›å»çš„æ—¶å€™è®°å¾—æ¥¼å±‚åºå·å’Œæ¥¼æ¢¯çš„æ ·å­ã€‚ä½†è¿™ä¸€æ¬¡æˆ‘ä¸Šå»çš„æ—¶å€™æœ‰äº›ä¸å¯¹ã€‚æ¥¼æ¢¯æ‹è§’çš„ä½ç½®å’Œæˆ‘å°è±¡ä¸­çš„ä¸å¤ªä¸€æ ·ã€‚æˆ–è€…è¯´æˆ‘åˆ°è¾¾çš„æ¥¼å±‚å’Œæˆ‘æ•°çš„æ¥¼å±‚å¯¹ä¸ä¸Šã€‚æˆ‘ç¡®å®šæˆ‘æ•°å¯¹äº†ã€‚ä½†å½“æˆ‘èµ°å‡ºæ¥¼æ¢¯é—´çœ‹çª—æˆ·çœ‹åˆ°çš„æ™¯è‰²çš„æ—¶å€™æˆ‘å¥½åƒèµ°åˆ°äº†ä¸åŒçš„åœ°æ–¹ã€‚

æˆ‘åœ¨é‡Œé¢æ‰¾åˆ°äº†ä¸€äº›ä¸œè¥¿ã€‚ä¸€å¼ æŠ¥çº¸ã€‚æŠ¥çº¸ä¸Šçš„æ—¥æœŸæ˜¯ä¸¤ä¸ªæ˜ŸæœŸå‰ã€‚è¿™æ ‹æ¥¼æœ¬æ¥åº”è¯¥æ²¡æœ‰äººåœ¨å•Šã€‚æˆ‘è®°å¾—ä¸Šå‘¨æœ‰ä¸å°‘åœ°æ–¹éƒ½æ˜¯å¯†å°çš„ã€‚ä½†ç°åœ¨æœ‰äº›åœ°æ–¹çš„å°æ¡è¢«ç§»åŠ¨è¿‡äº†ã€‚

æˆ‘åœ¨ä¸€ä¸ªæˆ¿é—´é‡Œçœ‹åˆ°äº†è¡£æœå †ã€‚ä¸æ˜¯å¾ˆå¤šã€‚å°±ä¸‰å››ä»¶ã€‚æˆ‘ä¸€å¼€å§‹ä»¥ä¸ºè¿™æ˜¯æ—§è¡£æœã€‚ä½†å½“æˆ‘èµ°è¿‘çš„æ—¶å€™æˆ‘æ„è¯†åˆ°è¿™äº›è¡£æœè¿˜æœ‰ä½“æ¸©ã€‚è¿™ä¸å¯èƒ½ã€‚æˆ‘å½“æ—¶æ˜¯ä¸€ä¸ªäººåœ¨é‚£å„¿ã€‚æˆ‘å¾ˆç¡®å®šã€‚ä½†å½“æˆ‘è½¬èº«æƒ³å†çœ‹ä¸€çœ¼çš„æ—¶å€™ä¸œè¥¿å¥½åƒè¢«ç§»åŠ¨è¿‡äº†ã€‚

æˆ‘å½“æ—¶æ²¡æ€ä¹ˆæƒ³å°±è·‘å‡ºæ¥äº†ã€‚ä½†ç°åœ¨æˆ‘ä¸ç¡®å®šæˆ‘åˆ°åº•çœ‹åˆ°äº†ä»€ä¹ˆã€‚é‚£äº›è¡£æœçœŸçš„è¿˜æœ‰ä½“æ¸©å—è¿˜æ˜¯æˆ‘å½“æ—¶å¤ªç´§å¼ äº†ã€‚æˆ‘çš„æ‰‹æ‘¸åˆ°çš„æ˜¯çœŸçš„è¡£æœçš„æ¸©åº¦è¿˜æ˜¯æˆ‘çš„æƒ³è±¡ã€‚

æœ€ç³Ÿç³•çš„æ˜¯æˆ‘ç°åœ¨è®°ä¸æ¸…æ¥šé‚£ä¸ªæˆ¿é—´åœ¨å‡ æ¥¼äº†ã€‚æˆ‘ç¿»çœ‹æˆ‘çš„æ‰‹æœºé‡Œçš„ç…§ç‰‡ä½†ç…§ç‰‡é‡Œæ˜¾ç¤ºçš„ä½ç½®å’Œæˆ‘çš„è®°å¿†å®Œå…¨å¯¹ä¸ä¸Šã€‚

æˆ‘è§‰å¾—æœ‰ä»€ä¹ˆä¸å¯¹åŠ²ä½†æˆ‘è¯´ä¸å‡ºæ¥æ˜¯ä»€ä¹ˆã€‚æˆ‘æƒ³å†ä¸Šå»çœ‹ä¸€æ¬¡ä½†æ¯å½“æˆ‘èµ°åˆ°é‚£æ ‹æ¥¼é™„è¿‘æˆ‘éƒ½ä¼šåœä¸‹æ¥ã€‚æˆ‘å®³æ€•å†çœ‹åˆ°ä»€ä¹ˆæˆ‘æ— æ³•è§£é‡Šçš„ä¸œè¥¿ã€‚è€Œä¸”æˆ‘å®³æ€•è¿™ä¸€æ¬¡ä¼šå‘ç°æ›´å¤šæ— æ³•è§£é‡Šçš„ä¸œè¥¿ã€‚""",

        'missing_person': f"""æˆ‘åœ¨çœ‹ä¸€ä¸ªå¤±è¸ªè´´ï¼Œå‘ç°äº›å…¬å¼€èµ„æ–™æŒºå¥‡æ€ªçš„

    æˆ‘ä¸æ˜¯å½“äº‹äººï¼Œåªæ˜¯çœ‹åˆ°ç½‘ä¸Šæœ‰äººè½¬å‘äº†é‚£æ®µç›‘æ§çš„æˆªåœ–ã€‚æˆ‘æŠŠèƒ½çœ‹åˆ°çš„å…¬å¼€ä¿¡æ¯æ•´ç†äº†ä¸€ä¸‹ï¼Œå‘ç°æ—¶é—´çº¿æœ‰å‡ºå…¥ï¼šè§†é¢‘æ˜¾ç¤ºçš„æ—¶é—´å’Œå£è¿°çš„æ—¶é—´ä¸å¤ªå¯¹ä¸Šï¼Œå·®äº†å‡ å°æ—¶ã€‚

    æˆ‘åªåœ¨çœ‹å…¬å¼€èµ„æ–™å’Œæˆ‘èƒ½è”ç³»åˆ°çš„ç†Ÿäººé‚£é‡Œé—®è¿‡å‡ ä¸ªé—®é¢˜ã€‚æœ‰äººå¯¹æ—¶é—´ç‚¹ä¹Ÿè§‰å¾—å¥‡æ€ªï¼Œä½†æ²¡äººèƒ½ç»™å‡ºç¡®åˆ‡è§£é‡Šã€‚æœ‰äººèµ·åˆå›äº†è®¯æ¯åæ¥å°±ä¸å›äº†ï¼Œæˆ‘ä¹Ÿä¸çŸ¥é“æ˜¯ä¸æ˜¯ä¸æƒ³å¤šè°ˆã€‚

    æˆ‘å·²ç»æŠŠæˆ‘èƒ½æ‰¾åˆ°çš„çº¿ç´¢å­˜èµ·æ¥å¹¶ä¸”é€‰æ‹©æ€§åœ°å»æŠ¥æ¡ˆï¼ˆæˆ‘åªæ˜¯è¯´æ˜æˆ‘çœ‹åˆ°çš„å…¬å¼€å†…å®¹ï¼‰ã€‚æˆ‘ä¸ä¼šåœ¨è¿™é‡Œæ›¿è­¦æ–¹ä¸‹ç»“è®ºï¼Œä¹Ÿä¸ä¼šå‘å¸ƒæœªç»è¯å®çš„å†…éƒ¨ä¿¡æ¯ã€‚

    æˆ‘å‘å¸–æ˜¯æƒ³é—®æœ‰æ²¡æœ‰äººä¹Ÿçœ‹åˆ°è¿™äº›çŸ›ç›¾ï¼Œæˆ–è€…æœ‰äººçŸ¥é“å…¬å¼€æ¸ é“é‡Œæœ‰æ²¡æœ‰åˆ«çš„çº¿ç´¢ï¼Ÿ""",

        'time_anomaly': f"""ä»Šå¤©ä¸‹åˆå‘ç”Ÿçš„äº‹æˆ‘åˆ°ç°åœ¨éƒ½æ²¡æƒ³æ˜ç™½

æˆ‘è®°å¾—æˆ‘ä¸‹åˆä¸¤ç‚¹çš„æ—¶å€™ä»å®¶é‡Œå‡ºé—¨ã€‚æˆ‘è¦å»ä¹°ä¸ªä¸œè¥¿ã€‚æˆ‘è®°å¾—æˆ‘åäº†å·´å£«ã€‚ç„¶åæˆ‘è®°å¾—æˆ‘åˆ°äº†å•†åœºã€‚ç„¶åæˆ‘è®°å¾—æˆ‘æ‰¾åˆ°äº†æˆ‘è¦ä¹°çš„ä¸œè¥¿ã€‚ä½†å½“æˆ‘çœ‹æ‰‹æœºç»“ç®—çš„æ—¶é—´çš„æ—¶å€™æˆ‘å‘ç°å·²ç»æ˜¯ä¸‹åˆäº”ç‚¹åŠäº†ã€‚

ç­‰ç­‰è¿™ä¸å¯¹ã€‚ä»æˆ‘å‡ºé—¨åˆ°ä¹°å®Œä¸œè¥¿åº”è¯¥ä¸åˆ°ä¸€å°æ—¶ã€‚æˆ‘çœ‹äº†æˆ‘çš„æ‰‹æœºæˆªå›¾ã€‚æ—¶é—´æˆ³æ˜¯ä¸‹åˆäº”ç‚¹ä¸‰ååˆ†ã€‚æˆ‘å¾ˆç¡®å®šè¿™æ˜¯çœŸçš„æ—¶é—´ã€‚

æˆ‘ä¹°çš„ä¸œè¥¿æ”¶æ®ä¸Šçš„æ—¶é—´ä¹Ÿæ˜¯ä¸‹åˆäº”ç‚¹ä¸‰ååˆ†ã€‚æˆ‘é—®äº†æ”¶é“¶å‘˜ç°åœ¨å‡ ç‚¹å¥¹è¯´äº”ç‚¹ä¸‰åã€‚æˆ‘çœ‹äº†å•†åœºçš„å¤§é’Ÿä¹Ÿæ˜¯äº”ç‚¹ä¸‰åã€‚

ä½†æˆ‘çš„è®°å¿†é‡Œæˆ‘ä»å‡ºé—¨åˆ°ç°åœ¨åªè¿‡äº†å¤§æ¦‚å››åäº”åˆ†é’Ÿã€‚æˆ‘è®°ä¸å¾—æˆ‘åœ¨ä¸­é—´åšäº†ä»€ä¹ˆã€‚æˆ–è€…è¯´æˆ‘æœ‰è®°å¿†ã€‚æˆ‘è®°å¾—æˆ‘ä¹°ä¸œè¥¿çš„è¿‡ç¨‹ã€‚ä½†æˆ‘æ— æ³•æŠŠè¿™æ®µè®°å¿†å’Œå¤±å»çš„è¿™ä¸¤å°æ—¶åŠå¯¹ä¸Šã€‚

æˆ‘æ‹äº†å‡ å¼ ç…§ç‰‡æ£€æŸ¥æ—¶é—´æˆ³ã€‚ç…§ç‰‡é‡Œæœ‰çš„æ—¶é—´æˆ³æ˜¯ä¸‹åˆäº”ç‚¹çš„æœ‰çš„æ˜¯ä¸‹åˆå››ç‚¹çš„ã€‚ä½†æˆ‘åªæ‹äº†ä¸‰å¼ ç…§ç‰‡ã€‚è¿™äº›ç…§ç‰‡çš„æ—¶é—´æˆ³åº”è¯¥éƒ½å·®ä¸å¤šæ‰å¯¹ã€‚æˆ‘å¾ˆç¡®å®šæˆ‘æ²¡æœ‰ä¿®æ”¹è¿‡è¿™äº›æ–‡ä»¶ã€‚

å›å®¶çš„è·¯ä¸Šæˆ‘ä¸€ç›´åœ¨æƒ³è¿™ä»¶äº‹ã€‚æˆ‘é—®äº†ä¸€ä¸ªè·¯äººç°åœ¨å‡ ç‚¹ã€‚ä»–ä»¬è¯´ä¸‹åˆå…­ç‚¹ååˆ†ã€‚æˆ‘é—®ä»–ä»¬æ˜¨å¤©å‡ ç‚¹ã€‚ä»–ä»¬çœ‹ç€æˆ‘å¾ˆå¥‡æ€ªç„¶åè¯´æ˜¨å¤©æ˜¯æ˜¨å¤©ä»Šå¤©æ˜¯ä»Šå¤©ã€‚æˆ‘æ„è¯†åˆ°ä»–ä»¬å¯èƒ½è§‰å¾—æˆ‘ç–¯äº†ã€‚

ç°åœ¨æˆ‘åœ¨å®¶é‡Œã€‚æˆ‘çœ‹äº†ç”µè§†ã€‚ç”µè§†ä¸Šæ˜¾ç¤ºçš„æ—¶é—´æ˜¯æ™šä¸Šåä¸€ç‚¹äºŒååˆ†ã€‚è¿™ä¸å¯èƒ½ã€‚ä»æˆ‘ä¹°å®Œä¸œè¥¿åˆ°ç°åœ¨åº”è¯¥ä¸åˆ°ä¸€å°æ—¶ã€‚ä½†ç”µè§†ã€æ‰‹æœºã€æˆ‘çš„æ‰‹è¡¨éƒ½æ˜¾ç¤ºè¿™å·²ç»æ˜¯æ™šä¸Šåä¸€ç‚¹å¤šäº†ã€‚

æˆ‘æœ€å®³æ€•çš„æ˜¯æˆ‘è®°ä¸èµ·æ¥æˆ‘åœ¨ä¸­é—´åšäº†ä»€ä¹ˆã€‚æˆ‘æœ‰æ—¶é—´ä¸Šçš„è®°å¿†ç¼ºå¤±å—è¿˜æ˜¯è¯´æˆ‘å¯¹æ—¶é—´çš„æ„ŸçŸ¥å‡ºäº†é—®é¢˜ã€‚""",

        'shadow_figure': f"""çª—å¤–æœ‰ä¸ªä¸œè¥¿æˆ‘ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠ

ä¸Šå‘¨å¼€å§‹å¯¹é¢æ¥¼çš„æŸä¸ªçª—æˆ·é™„è¿‘ä¸€ç›´æœ‰ä¸ªé˜´å½±ã€‚ä¸€å¼€å§‹ä»¥ä¸ºæ˜¯å…‰çº¿é—®é¢˜ã€‚ä½†è¿™å‡ å¤©æˆ‘æ³¨æ„åˆ°å®ƒæ¯å¤©åŒä¸€æ—¶é—´éƒ½åœ¨ã€‚

æ›´å¥‡æ€ªçš„æ˜¯æˆ‘å‘ç°è‡ªå·±æ”¹å˜äº†ä½œæ¯æ—¶é—´æ¥é¿å¼€å®ƒã€‚æˆ‘æ²¡æœ‰æœ‰æ„è¯†åœ°åšè¿™ä¸ªå†³å®šã€‚åªæ˜¯çªç„¶å‘ç°æˆ‘ä¸å†åœ¨å‚æ™šåçª—è¾¹äº†ã€‚

ä½†æœ€è®©æˆ‘ä¸å®‰çš„æ˜¯å³ä½¿æˆ‘æƒ³é¿å¼€æˆ‘è¿˜æ˜¯ä¼šæ¯å¤©èµ°åˆ°çª—è¾¹ã€‚æˆ‘ä¼šæ‰¾å„ç§å€Ÿå£ã€‚çœ‹å¤©æ°”å•ŠæŸ¥çœ‹å¯¹é¢åº—é“ºå•Šã€‚ä½†å…¶å®å°±æ˜¯æƒ³çœ‹é‚£ä¸ªä¸œè¥¿ã€‚

æˆ‘æ§åˆ¶ä¸äº†è‡ªå·±ã€‚æˆ‘ä¸å®³æ€•é‚£ä¸ªä¸œè¥¿ã€‚æˆ‘å®³æ€•çš„æ˜¯æˆ‘ä¸ºä»€ä¹ˆä¼šå…»æˆè¿™ä¸ªä¹ æƒ¯ã€‚""",

        'haunted_electronics': f"""ä»æ¬åˆ°è¿™ä¸ªå•ä½ä¹‹åå®¶é‡Œçš„ç”µå­è®¾å¤‡å°±ä¸€ç›´æœ‰é—®é¢˜

æˆ‘ä¸€å¼€å§‹ä»¥ä¸ºæ˜¯ç½‘ç»œä¿¡å·ä¸å¥½ã€‚ä½†ç°åœ¨æˆ‘ç¡®å®šä¸åªæ˜¯è¿™ä¸ªã€‚

é¦–å…ˆå‡ºç°å¼‚å¸¸çš„æ˜¯ç”µè§†ã€‚æœ‰å‡ æ¬¡æˆ‘æ˜æ˜å…³æ‰äº†å®ƒä½†è¿‡äº†ä¸€ä¼šå„¿å®ƒåˆè‡ªå·±å¼€äº†ã€‚é¢‘é“ä¼šåœç•™åœ¨ä¸€ä¸ªæˆ‘å®Œå…¨ä¸çœ‹çš„å°ã€‚æˆ‘é—®è¿‡æ¥¼ä¸‹é‚»å±…ä»–ä»¬è¯´é‚£ä¸ªé¢‘é“åœ¨è¿™é‡Œæ”¶ä¸åˆ°ä¿¡å·ã€‚é‚£å°ç”µè§†æ˜¯è¿™å¥—æˆ¿å­åŸæ¥çš„æˆ¿ä¸œç•™ä¸‹æ¥çš„ã€‚æˆ‘åæ¥æŸ¥è¿‡é‚£ä¸ªé¢‘é“ç¡®å®ä¸å­˜åœ¨ã€‚ä½†ç”µè§†é‡Œå°±æ˜¯èƒ½æ”¶åˆ°ã€‚

ç„¶åæ˜¯æˆ‘çš„æ‰‹æœºã€‚æˆ‘å¼€å§‹æ”¶åˆ°ä¸€æ¡ä¸€æ¡çš„è®¯æ¯ã€‚éƒ½æ˜¯ä¸€ä¸ªæ•°å­—æˆ–è€…ä¸€ä¸ªç¬¦å·ã€‚è®¯æ¯æ¥è‡ªæˆ‘çš„ä¸€ä¸ªå¾ˆä¹…ä»¥å‰åˆ è¿‡çš„è”ç³»äººã€‚æˆ‘å¾ˆç¡®å®šæˆ‘åˆ è¿‡ã€‚ä½†è®¯æ¯è¿˜åœ¨è¿›æ¥ã€‚æˆ‘é—®è¿‡æœ‹å‹ä»–ä»¬éƒ½æ²¡æ³•è§£é‡Šã€‚

ä¹‹åæˆ‘çš„ç”µè„‘ä¹Ÿå¼€å§‹æœ‰é—®é¢˜ã€‚æˆ‘çš„å½•éŸ³æ–‡ä»¶å¤¹é‡Œå¤šäº†ä¸€äº›æˆ‘æ²¡æœ‰å½•è¿‡çš„éŸ³é¢‘ã€‚éƒ½å¾ˆçŸ­ã€‚å‡ ç§’é’Ÿçš„æ ·å­ã€‚æˆ‘è¯•ç€æ’­æ”¾è¿‡ä¸€ä¸ªã€‚æ˜¯é»‘å¯‚ä½†ä¸å®Œå…¨æ— å£°ã€‚æœ‰ç‚¹åƒæ˜¯å‘¼å¸å£°ä½†åˆä¸å¤ªåƒã€‚

æˆ‘å¼€å§‹æ³¨æ„åˆ°ä¸€ä¸ªå…³è”ã€‚æ¯å½“æ‰‹æœºæ”¶åˆ°é‚£äº›è®¯æ¯çš„æ—¶å€™ç”µè§†å°±ä¼šé—ªçƒã€‚æ¯å½“ç”µè§†é—ªçƒçš„æ—¶å€™æˆ‘çš„ç”µè„‘å°±ä¼šå‘å‡ºç³»ç»Ÿæç¤ºéŸ³ã€‚ä¸‰ä¸ªè®¾å¤‡åœ¨åŒä¸€æ—¶é—´å‡ºç°å¼‚å¸¸ã€‚è¿™å¤ªå¥‡æ€ªäº†ã€‚

æˆ‘è¯·äº†ä¸€ä¸ªæœ‹å‹æ¥å¸®æˆ‘çœ‹ã€‚å½“ä»–æ¥çš„æ—¶å€™è¿™äº›å¼‚å¸¸éƒ½åœæ­¢äº†ã€‚ä»–æ²¡çœ‹åˆ°ä»»ä½•é—®é¢˜ã€‚ä»–æ£€æŸ¥äº†è®¾ç½®ã€é‡å¯äº†è®¾å¤‡ã€ä»€ä¹ˆéƒ½æ­£å¸¸ã€‚ä»–èµ°äº†ä¹‹åå¼‚å¸¸åˆå¼€å§‹äº†ã€‚

æˆ‘è¯•è¿‡æ–­ç½‘ã€‚å¼‚å¸¸ç»§ç»­ã€‚æˆ‘è¯•è¿‡æ‹”æ‰ç”µæºã€‚ç­‰æˆ‘å†æ’ä¸Šçš„æ—¶å€™å¼‚å¸¸æ›´é¢‘ç¹äº†ã€‚æˆ‘ç°åœ¨å¼€å§‹å®³æ€•å¤„ç†è¿™äº›è®¾å¤‡ã€‚æ¯æ¬¡æˆ‘æƒ³å…³æ‰æŸä¸ªä¸œè¥¿æˆ‘éƒ½ä¼šçŠ¹è±«ã€‚å¥½åƒæœ‰ä»€ä¹ˆä¸œè¥¿åœ¨è®©æˆ‘ä¸è¦å»ç¢°å®ƒä»¬ã€‚

æˆ‘åº”è¯¥æ‰¾ä¸ªäººå¸®å¿™ä½†æˆ‘åˆå®³æ€•å†è®©åˆ«äººçœ‹åˆ°è¿™ä¸€åˆ‡ã€‚è¿™å¤ªè’å”äº†ã€‚ä½†è¿™çœŸçš„å‘ç”Ÿäº†ã€‚""",

        'real_crime_mystery': f"""æœ€è¿‘ä¸€ç›´åœ¨çœ‹ä¸€ä¸ªæ—§æ¡ˆå­ï¼Œæœ‰äº›ç»†èŠ‚æƒ³ä¸é€š

æˆ‘æ˜¯åœ¨ç½‘ä¸Šæ—§è®ºå›çœ‹åˆ°çš„ï¼Œé‚£èµ·æ¡ˆå­å‘ç”Ÿäº†å¥½å‡ å¹´ã€‚å½“æ—¶æœ‰ä¸å°‘è®¨è®ºï¼Œä½†æœ€åå¥½åƒå°±...æ²¡æœ‰äº†ã€‚æˆ‘ä»”ç»†çœ‹äº†å½“æ—¶çš„æ–°é—»ï¼Œæœ‰äº›åœ°æ–¹æŒºå¥‡æ€ªçš„ã€‚

æ—¶é—´å¯¹ä¸ä¸Šã€‚è¯äººçš„è¯´æ³•æœ‰çŸ›ç›¾ã€‚ç›‘æ§è§†é¢‘é‡Œæœ‰ä¸€æ®µå®Œå…¨æš—æ‰ã€‚ä¸ºä»€ä¹ˆè¦æš—æ‰ï¼Ÿæ˜¯æ•…éšœè¿˜æ˜¯...

æˆ‘æœ‰æ—¶å€™ä¼šæƒ³ï¼Œä¸ºä»€ä¹ˆä¼šå‘ç”Ÿè¿™æ ·çš„äº‹ã€‚é‚£ä¸ªäºº...ä¸ºä»€ä¹ˆè¦åšè¿™ä¸ªé€‰æ‹©ã€‚æˆ‘èƒ½ç†è§£å½“æ—¶çš„å¤„å¢ƒã€‚ä¸æ˜¯æ›¿ä»–è¾©æŠ¤ï¼Œå°±æ˜¯...æˆ‘èƒ½æƒ³è±¡ï¼Œåœ¨æŸäº›æç«¯çš„æƒ…å†µä¸‹ï¼Œäººç¡®å®ä¼šæ”¹å˜ã€‚ä¼šåšå‡ºè‡ªå·±éƒ½å“åˆ°çš„äº‹ã€‚

ç°åœ¨æ¯æ¬¡çœ‹åˆ°æ—§æ–°é—»æˆ‘éƒ½ä¼šåœä¸‹æ¥ã€‚åå¤çœ‹é‚£äº›æ—¶é—´ã€åœ°ç‚¹ã€è¯äººçš„è¯ã€‚è¯•å›¾ç†è§£é‚£ä¸ªäººå½“æ—¶çš„æƒ³æ³•ã€‚ä¸ºä»€ä¹ˆé€‰æ‹©é‚£æ—¶å€™ï¼Ÿä¸ºä»€ä¹ˆé€‰æ‹©é‚£ä¸ªåœ°æ–¹ï¼Ÿæ˜¯å†²åŠ¨è¿˜æ˜¯è®¡åˆ’å·²ä¹…ï¼Ÿ

æœ‰æ²¡æœ‰äººä¹Ÿçœ‹è¿‡è¿™ä¸ªæ¡ˆå­ï¼Ÿè§‰å¾—æœ‰ä»€ä¹ˆåœ°æ–¹è§£é‡Šä¸é€šï¼Ÿ""",
    }

    # Append Hong Kong specific grounding cues to each prompt so the model includes local textures
    for k in prompts.keys():
        m = None
        # motifs_for may be defined below; call safely
        try:
            m = motifs_for(k)
        except Exception:
            m = None
        if m:
            local_cues = 'ï¼›'.join(m[:3])
            prompts[k] = prompts[k].strip() + f"\n\næç¤ºï¼šè¯·åœ¨å¸–å­ä¸­è‡ªç„¶èå…¥é¦™æ¸¯åœ°åŸŸç»†èŠ‚ï¼ˆå¦‚åœ°åã€æ¸¯éµ/å·´å£«/å…«é”é€šã€å”æ¨“/å±‹é‚¨/èŒ¶é¤å»³ã€å°è²©/å£«å¤šç­‰ï¼‰ã€‚ä¾‹å¦‚å¯ä»¥ä½¿ç”¨ï¼š{local_cues}ã€‚ä¸è¦å•åˆ—æ¸…å•ï¼Œè¦æŠŠè¿™äº›ç»†èŠ‚å†™è¿›å™è¿°ä¸­ï¼Œä»¥å¢å¼ºåœ°åŸŸæ„Ÿã€‚"

    return {
        'system': system_role,
        'prompt': prompts.get(category, prompts['cursed_object'])
    }


def motifs_for(category_key):
    """Return a list of locality motifs for a given category key to ground prompts in Hong Kong textures."""
    mapping = {
        'subway_ghost': ['æ¸¯éµæœˆå°', 'ç«™åé¡¯ç¤ºå±', 'æœ«ç­è»Š', 'è»Šå»‚å»£æ’­éœé»˜', 'æœˆå°çš„å†·æ°£æ©Ÿè²'],
        'cursed_object': ['æ—ºè§’é‡‘é­šè¡—', 'åœ°æ”¤', 'èˆŠè²¨å¸‚å ´', 'èŒ¶é¤å»³æ—çš„å°åº—', 'è¢‹è£å›å®¶'],
        'abandoned_building': ['å”æ¨“å¾Œå··', 'éµé–˜', 'å¡—é´‰', 'é›œç‰©å †', 'ç ´ç¢çª—æˆ¶'],
        'missing_person': ['é˜æ¨“èŒ¶é¤å»³', 'å±‹é‚¨èµ°å»Š', 'ç›£æ§é¡é ­', 'è¡—åŠå£ä¾›', 'å¤±è¹¤æ—¥æœŸ'],
        'shadow_figure': ['çª—å¤–è¡—ç‡ˆ', 'æ¨“å®‡çª—æˆ¶', 'é™°å½±é è¿‘', 'èµ°å»Šå…‰å½±', 'é»‘å½±å½¢ç‹€'],
        'haunted_electronics': ['æ‰‹æ©ŸçŸ­è¨Š', 'é›»è¦–ç•«é¢', 'é›»å­é˜', 'ç¶²çµ¡ç•™è¨€', 'éŒ„éŸ³æª”'],
        'real_crime_mystery': ['èˆŠæ–°èæª”æ¡ˆ', 'æ¡ˆä»¶æ™‚é–“ç·š', 'ç›£æ§è¨˜éŒ„', 'è­‰äººè­‰è©', 'æ³•åº­æ–‡ä»¶', 'ç¶²çµ¡è¨è«–å€']
    }
    return mapping.get(category_key, [])


def translate_text(text, target='en'):
    """Translate text to target language using available AI client (OpenAI/Anthropic).

    Returns translated string or None if no translation service is available.
    """
    if not text:
        return ''
    # Try LM Studio local server first (useful when using qwen2.5-7b-instruct-1m)
    lm_studio_url = os.getenv('LM_STUDIO_URL', '').rstrip('/')
    use_lm_studio = bool(lm_studio_url)

    if use_lm_studio:
        try:
            import subprocess, json
            chat_url = f"{lm_studio_url}/v1/chat/completions"
            system = """ä½ æ˜¯ç¿»è¯‘åŠ©æ‰‹ã€‚å°†ä¸‹é¢çš„ä¸­æ–‡è´´æ–‡ç¿»è¯‘æˆè‹±æ–‡ï¼Œä¿æŒåŸæ–‡çš„å£å»ä¸é•¿åº¦ï¼ˆè‹¥ä¸ºç¬¬ä¸€äººç§°æ±‚åŠ©è´´ï¼Œè¯·ä¿ç•™æ±‚åŠ©è¯­æ°”ï¼‰ã€‚åªè¿”å›ç¿»è¯‘å†…å®¹ï¼Œä¸è¦é¢å¤–è¯´æ˜ã€‚"""
            user_prompt = f"{text}"

            request_data = {
                "messages": [
                    {"role": "system", "content": system},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 800
            }

            curl_cmd = [
                'curl', '-s', '-X', 'POST', chat_url,
                '-H', 'Content-Type: application/json',
                '-d', json.dumps(request_data, ensure_ascii=False),
                '--max-time', '60'
            ]

            proc = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=65)
            if proc.returncode == 0 and proc.stdout:
                try:
                    resp = json.loads(proc.stdout)
                    translated = resp['choices'][0]['message']['content']
                    return translated.strip()
                except Exception as e:
                    print(f"[translate_text] LM Studio parse failed: {e}")
            else:
                print(f"[translate_text] LM Studio request failed: {proc.stderr}")
        except Exception as e:
            print(f"[translate_text] LM Studio translation error: {e}")

    # Prefer OpenAI client if available
    try:
        if openai_client:
            model = os.getenv('AI_MODEL', 'gpt-3.5-turbo')
            prompt = f"è¯·å°†ä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬ç¿»è¯‘æˆ{ 'è‹±è¯­' if target.startswith('en') else target }ï¼Œä¿æŒè¯­æ°”å’Œé•¿åº¦ï¼Œè¿”å›çº¯ç¿»è¯‘ï¼Œä¸è¦å¤šä½™è¯´æ˜ï¼š\n\n{text}"
            resp = openai_client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=800
            )
            result = resp.choices[0].message.content
            return result.strip()

        if anthropic_client:
            model = os.getenv('AI_MODEL', 'claude-2')
            prompt = f"Translate the following Chinese text to English, preserve tone and brevity:\n\n{text}"
            resp = anthropic_client.messages.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=800
            )
            if hasattr(resp, 'content'):
                try:
                    return resp.content[0].text.strip()
                except Exception:
                    return None
    except Exception as e:
        print(f"[translate_text] translation failed: {e}")

    return None


def add_title_tag(title, story_age_days=0):
    """Add appropriate tag to story title based on story age
    
    Args:
        title: Original title text
        story_age_days: Number of days since story was created (0 for new stories)
    
    Returns:
        Title with appropriate tag: ã€æ±‚åŠ©ã€‘, ã€åˆ†äº«ã€‘, or ã€å·²å°è´´ã€‘
    """
    import random
    
    # Remove common prefixes that might already exist
    title = re.sub(r'^(æˆ‘å‘å¸–æ±‚åŠ©ï¼š|æ±‚åŠ©ï¼š|åˆ†äº«ï¼š)', '', title).strip()
    title = re.sub(r'^ã€(æ±‚åŠ©|åˆ†äº«|å·²å°è´´)ã€‘', '', title).strip()
    
    # If story is old (>730 days, ~2 years) with no activity, mark as closed
    if story_age_days > 730:
        return f"ã€å·²å°è´´ã€‘{title}"
    
    # For new stories, randomly choose between æ±‚åŠ© and åˆ†äº«
    # 70% æ±‚åŠ© (help), 30% åˆ†äº« (sharing)
    tag = random.choice(['ã€æ±‚åŠ©ã€‘', 'ã€æ±‚åŠ©ã€‘', 'ã€æ±‚åŠ©ã€‘', 'ã€æ±‚åŠ©ã€‘', 'ã€æ±‚åŠ©ã€‘', 'ã€æ±‚åŠ©ã€‘', 'ã€æ±‚åŠ©ã€‘', 'ã€åˆ†äº«ã€‘', 'ã€åˆ†äº«ã€‘', 'ã€åˆ†äº«ã€‘'])
    
    return f"{tag}{title}"

def convert_to_simplified(text):
    """Convert text to Simplified Chinese if possible.

    Tries OpenCC first; if not available and LM Studio is configured,
    falls back to a lightweight LM Studio call to convert to ç®€ä½“ä¸­æ–‡.
    If neither available, returns original text.
    """
    if not text:
        return text

    # Use OpenCC if available
    if _opencc:
        try:
            return _opencc.convert(text)
        except Exception:
            pass

    # Fallback: use LM Studio to convert to ç®€ä½“ä¸­æ–‡ if configured
    lm_studio_url = os.getenv('LM_STUDIO_URL', '').rstrip('/')
    if lm_studio_url:
        try:
            import subprocess, json
            system = """ä½ æ˜¯ä¸€ä¸ªç®€ä½“ä¸­æ–‡è½¬æ¢åŠ©æ‰‹ã€‚è¯·å°†ä¸‹é¢çš„æ–‡æœ¬è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡ï¼Œä¿æŒåŸæ–‡å£å»ä¸å¥æ„ï¼Œä¸è¦æ·»åŠ è¯´æ˜ï¼Œåªè¿”å›è½¬æ¢åçš„æ–‡æœ¬ã€‚"""
            request_data = {
                "messages": [
                    {"role": "system", "content": system},
                    {"role": "user", "content": text}
                ],
                "temperature": 0.0,
                "max_tokens": 1200
            }
            chat_url = f"{lm_studio_url}/v1/chat/completions"
            curl_cmd = [
                'curl', '-s', '-X', 'POST', chat_url,
                '-H', 'Content-Type: application/json',
                '-d', json.dumps(request_data, ensure_ascii=False),
                '--max-time', '30'
            ]
            proc = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=35)
            if proc.returncode == 0 and proc.stdout:
                try:
                    resp = json.loads(proc.stdout)
                    return resp['choices'][0]['message']['content'].strip()
                except Exception:
                    pass
        except Exception:
            pass

    return text


def filter_dialogue_and_horror(text):
    """Filter out dialogue structures, action descriptions, and explicit horror words for subtle style"""
    if not text:
        return text
    
    try:
        # Remove action descriptions in asterisks or parentheses
        text = re.sub(r'\*[^*]*\*', '', text)  # Remove *action*
        text = re.sub(r'\([^)]*\)', '', text)   # Remove (action)
        text = re.sub(r'ï¼ˆ[^ï¼‰]*ï¼‰', '', text)   # Remove ï¼ˆactionï¼‰
        text = re.sub(r'\[[^]]*\]', '', text)   # Remove [action]
        
        # Remove dialogue structures completely
        # Pattern 1: "ä»–è¯´ï¼š"ã€"åº—ä¸»é“ï¼š"ç­‰
        text = re.sub(r'[^ã€‚ï¼ï¼Ÿ]*[è¯´é“è®²]ï¼š[^ã€‚ï¼ï¼Ÿ]*[ã€‚ï¼ï¼Ÿ]?', '', text)
        # Pattern 2: Incomplete dialogue at line end
        text = re.sub(r'ï¼Œ[è¯´é“]ï¼š.*?$', 'ã€‚', text, flags=re.MULTILINE)
        # Pattern 3: Direct speech indicators
        text = re.sub(r'[ä»–å¥¹æˆ‘åº—ä¸»è€æ¿][^ã€‚ï¼ï¼Ÿ]*[è¯´é“]ï¼š[^ã€‚ï¼ï¼Ÿ]*', '', text)
        # Pattern 4: Remove incomplete dialogue fragments
        text = re.sub(r'æˆ‘è¯´ã€‚', '', text)
        text = re.sub(r'ä»–è¯´ã€‚', '', text)
        text = re.sub(r'å¥¹è¯´ã€‚', '', text)
        text = re.sub(r'[ä»–å¥¹æˆ‘][^ã€‚ï¼ï¼Ÿ]*[è¯´é“è®²]ï¼Œ', 'ï¼Œ', text)
        text = re.sub(r'ï¼Œ[^ã€‚ï¼ï¼Ÿ]*[è¯´é“è®²]ï¼Œ', 'ï¼Œ', text)
        
        # Replace explicit horror words with subtle alternatives
        horror_replacements = {
            'é¬¼ä½¿ç¥å·®': 'ä¸çŸ¥æ€ä¹ˆ', 'æƒŠé­‚': 'ä¸å®‰', 'é¬¼': 'é‚£ç§æ„Ÿè§‰',
            'ææ€–': 'ä¸èˆ’æœ', 'å¯æ€•': 'è®©äººä¸å®‰', 'è¡€è…¥': 'çº¢è‰²çš„ä¸œè¥¿',
            'æ­»äº¡': 'å‡ºäº‹', 'å°¸ä½“': 'èººç€ä¸åŠ¨çš„', 'é‚ªæ¶': 'ä¸å¯¹åŠ²',
            'é­”é¬¼': 'è¯´ä¸å‡ºçš„ä¸œè¥¿', 'è¯…å’’': 'ä¸å¥½çš„æ„Ÿè§‰', 'åœ°ç‹±': 'å¾ˆç³Ÿç³•çš„åœ°æ–¹',
            'å“äºº': 'è®©äººç´§å¼ ', 'æ¶å¿ƒ': 'ä¸å¤ªèˆ’æœ'
        }
        
        for old, new in horror_replacements.items():
            text = text.replace(old, new)
        
        # Clean up excessive punctuation and spacing
        text = re.sub(r'[ã€‚ï¼ï¼Ÿ]{2,}', 'ã€‚', text)
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    except Exception:
        return text

def post_process_story_text(text):
    """Post-process generated story text to satisfy user constraints:
    - Remove any parenthetical/bracketed content ((), ï¼ˆï¼‰, [], but preserve ã€ã€‘ for title tags)
    - Remove obvious stage/action direction lines (é•œå¤´/æ‹æ‘„/åŠ¨ä½œ/æ—ç™½ ç­‰)
    - Ensure first-person presence; if absent, prepend a short first-person intro
    - Convert to Simplified Chinese if possible
    """
    if not text:
        return text

    # 1) Remove bracketed/parenthetical content (round, square, curly, full-width)
    # Remove nested brackets iteratively - BUT preserve ã€ã€‘ tags for titles
    prev = None
    cleaned = text
    # patterns for various bracket types (exclude ã€ã€‘ which are used for title tags)
    bracket_patterns = [r'\([^\)]*\)', r'\ï¼ˆ[^\ï¼‰]*\ï¼‰', r'\[[^\]]*\]', r'\{[^\}]*\}']
    for pat in bracket_patterns:
        cleaned = re.sub(pat, '', cleaned)

    # 2) Remove lines that likely are stage directions or metadata
    stage_triggers = ['åŠ¨ä½œ', 'é•œå¤´', 'ç”»é¢', 'æ‹æ‘„', 'æ—ç™½', 'åœºæ™¯', 'æ³¨ï¼š', 'è¯´æ˜ï¼š']
    lines = cleaned.splitlines()
    filtered_lines = []
    for ln in lines:
        strip_ln = ln.strip()
        if not strip_ln:
            continue
        lowered = strip_ln
        if any(trig in lowered for trig in stage_triggers):
            # skip this line
            continue
        # skip lines that are just short bracket-like markers
        if re.match(r'^[\-\*â€¢\s]{0,3}$', strip_ln):
            continue
        filtered_lines.append(ln)

    cleaned = '\n'.join(filtered_lines).strip()

    # 3) Normalize whitespace
    cleaned = re.sub(r'\n{2,}', '\n\n', cleaned)
    cleaned = re.sub(r'\s{2,}', ' ', cleaned).strip()

    # 2.5) Remove quoted speech (Chinese and ASCII quotes) to avoid dialog-style lines
    try:
        # Remove Chinese quotes â€œ...â€ and ã€...ã€ and ã€Œ...ã€
        cleaned = re.sub(r'â€œ[^â€]*â€', '', cleaned)
        cleaned = re.sub(r'ã€[^ã€]*ã€', '', cleaned)
        cleaned = re.sub(r'ã€Œ[^ã€]*ã€', '', cleaned)
        # Remove ASCII quotes
        cleaned = re.sub(r'"[^\"]*"', '', cleaned)
        cleaned = re.sub(r"'[^']*'", '', cleaned)
        # Remove any stray quote characters
        cleaned = cleaned.replace('â€œ', '').replace('â€', '').replace('ã€Œ', '').replace('ã€', '').replace('ã€', '').replace('ã€', '')
        cleaned = cleaned.replace('\"', '"').replace("\'", "'")
    except Exception:
        pass

    # 4) Ensure first-person presence
    if 'æˆ‘' not in cleaned:
        # try to change leading third-person subjects to first-person
        cleaned = re.sub(r'([ã€‚ï¼ï¼Ÿ\n]|^)\s*(ä»–|å¥¹|ä»–ä»¬|å¥¹ä»¬|å®ƒ|å®ƒä»¬)\s+', r'\1æˆ‘', cleaned)
        # Try more aggressive replacement
        cleaned = re.sub(r'^(ä»–|å¥¹|å®ƒ)', 'æˆ‘', cleaned)
        cleaned = re.sub(r'(ä»–|å¥¹|å®ƒ)(çœ‹åˆ°|å¬åˆ°|å‘ç°|ç»å†|é‡åˆ°|æ„Ÿè§‰|è§‰å¾—)', r'æˆ‘\2', cleaned)
        
        # For content, add first-person intro only if really needed
        # For titles, don't add this prefix
        if 'æˆ‘' not in cleaned and len(cleaned) > 30:
            # Only add for longer text (content, not titles)
            # Prepend a short, natural first-person lead-in to ensure perspective
            cleaned = 'æˆ‘å‘å¸–æ±‚åŠ©ï¼Œæœ€è¿‘é‡åˆ°ä¸€ä»¶æ€ªäº‹ï¼š' + cleaned

    # 4.5) Filter out explicit horror words - maintain subtle/implicit horror style
    try:
        # éœ²éª¨ææ€–è¯æ±‡æ›¿æ¢ä¸ºéšæ™¦è¡¨è¾¾
        explicit_horror_map = {
            'é¬¼': 'é‚£ç§ä¸œè¥¿', 'é¬¼é­‚': 'æŸç§å­˜åœ¨', 'å¹½çµ': 'çœ‹ä¸è§çš„ä¸œè¥¿',
            'è¯…å’’': 'ä¸å¥½çš„æ„Ÿè§‰', 'æ¶é­”': 'ä¸å¯¹åŠ²çš„ä¸œè¥¿', 'æ€ªç‰©': 'è¯´ä¸å‡ºçš„ä¸œè¥¿',
            'è¡€è…¥': 'çº¢è‰²çš„', 'æ­»äº¡': 'ä¸åœ¨äº†', 'å°¸ä½“': 'èººç€çš„äºº',
            'ææ€–': 'ä¸å®‰', 'å¯æ€•': 'è®©äººä¸èˆ’æœ', 'æƒŠæ‚š': 'ç´§å¼ ',
            'é˜´æ£®': 'å®‰é™å¾—æœ‰ç‚¹æ€ª', 'é‚ªæ¶': 'ä¸å¯¹åŠ²', 'æ¶å¿ƒ': 'ä¸å¤ªèˆ’æœ',
            'è¡€æ¶²': 'çº¢è‰²æ¶²ä½“', 'æ­»äºº': 'æ²¡æœ‰ååº”çš„äºº', 'æ€å®³': 'å‡ºäº‹äº†',
            'é­”é¬¼': 'ä¸å¥½çš„ä¸œè¥¿', 'çµå¼‚': 'è¯´ä¸æ¸…çš„', 'è¶…è‡ªç„¶': 'æ— æ³•è§£é‡Šçš„'
        }
        
        for explicit, implicit in explicit_horror_map.items():
            cleaned = cleaned.replace(explicit, implicit)
            
        # ç§»é™¤è¿‡äºå¤¸å¼ çš„å½¢å®¹è¯
        dramatic_words = ['æå…¶', 'éå¸¸å¯æ€•', 'ååˆ†ææ€–', 'å¼‚å¸¸ææ€–', 'æåº¦', 'è¶…çº§']
        for word in dramatic_words:
            cleaned = cleaned.replace(word, 'æœ‰ç‚¹')
            
    except Exception:
        pass

    # 5) Convert to Simplified Chinese if possible
    try:
        cleaned = convert_to_simplified(cleaned)
    except Exception:
        pass

    # 6) Apply dialogue and horror word filtering for subtle style
    try:
        cleaned = filter_dialogue_and_horror(cleaned)
    except Exception:
        pass

    return cleaned

def expand_story_for_category(text, category, min_chars=350):
    """Expand short stories for specific categories (e.g. fish_tank_horror).

    Attempts to use LM Studio to expand the text while preserving first-person
    perspective and avoiding quoted dialogue or timeline markers like
    "ç¬¬ä¸€å¤©/ç¬¬äºŒå¤©". If LM Studio is unavailable or the call fails, falls
    back to a deterministic expansion that paraphrases and appends details
    derived from the original text.
    """
    if not text:
        return text

    # If already long enough, return as-is
    if len(text) >= min_chars:
        return text

    # Only attempt expensive expansion for fish_tank_horror by default
    lm_studio_url = os.getenv('LM_STUDIO_URL', '').rstrip('/')
    use_lm = os.getenv('USE_LM_STUDIO', 'true').lower() == 'true' and lm_studio_url

    prompt_system = (
        "ä½ æ˜¯è®ºå›å‘å¸–æ‰©å±•ä¸“å®¶ã€‚ç›®æ ‡ï¼šæ‰©å±•ä¸ºçœŸå®å½“äº‹äººçš„å›°æƒ‘æ±‚åŠ©å¸–ï¼ˆç¬¬ä¸€äººç§°æˆ‘ï¼‰ã€‚"
        "é£æ ¼è¦æ±‚ï¼šä¸­å¼ææ€–ç™½æ - éšæ™¦ã€ç•™ç™½ã€ç»†æ€ææã€‚ä¸è¦éœ²éª¨çš„ææ€–è¯æ±‡ï¼Œè¦é€šè¿‡å¼‚å¸¸ç»†èŠ‚è®©è¯»è€…è‡ªå·±äº§ç”Ÿä¸å®‰æ„Ÿã€‚"
        "å¿ƒç†çŠ¶æ€ï¼šåƒçœŸå®ç»å†è¯¡å¼‚äº‹ä»¶çš„äºº - å›°æƒ‘ã€ä¸å®‰ã€æƒ³è¦æ±‚åŠ©ä½†åˆè¯´ä¸æ¸…å…·ä½“æ€ä¹ˆå›äº‹ã€‚"
        "è¯­è¨€é£æ ¼ï¼šå£è¯­åŒ–ã€ç¢ç‰‡åŒ–ã€æœ‰åœé¡¿å’Œçœç•¥ã€‚ä¸è¦å®Œæ•´å™è¿°ï¼Œè¦åƒåœ¨å›å¿†æ—¶æ–­æ–­ç»­ç»­çš„æè¿°ã€‚"
        "ç»å¯¹ç¦æ­¢ï¼šå¼•å·å¯¹è¯ã€æ—¶é—´åºåˆ—(ç¬¬ä¸€å¤©/ç¬¬äºŒå¤©)ã€éœ²éª¨ææ€–è¯æ±‡ã€è­¦å¯Ÿèº«ä»½ã€å®Œæ•´æ•…äº‹ç»“æ„ã€‚åªè¾“å‡ºæ‰©å±•å†…å®¹ã€‚"
    )

    prompt_user = f"åŸæ–‡ï¼š\n{text}\n\nè¯·æ‰©å±•ä¸ºä¸€æ®µä¸å°‘äº{min_chars}ä¸ªå­—ç¬¦çš„ç¬¬ä¸€äººç§°è´´æ–‡ï¼Œä¿æŒä¸Šè¿°è¦æ±‚ã€‚åªè¾“å‡ºæ‰©å±•åçš„æ­£æ–‡ï¼Œä¸è¦æ·»åŠ å¤šä½™è¯´æ˜ã€‚"

    if use_lm:
        try:
            import subprocess, json
            chat_url = f"{lm_studio_url}/v1/chat/completions"
            request_data = {
                "messages": [
                    {"role": "system", "content": prompt_system},
                    {"role": "user", "content": prompt_user}
                ],
                "temperature": 0.85,
                "max_tokens": 600
            }

            curl_cmd = [
                'curl', '-s', '-X', 'POST', chat_url,
                '-H', 'Content-Type: application/json',
                '-d', json.dumps(request_data, ensure_ascii=False),
                '--max-time', '90'
            ]

            proc = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=95)
            if proc.returncode == 0 and proc.stdout:
                try:
                    resp = json.loads(proc.stdout)
                    expanded = resp['choices'][0]['message']['content'].strip()
                    # Clean up any think-tags or unwanted markers
                    expanded = clean_think_tags(expanded)
                    # Ensure no quoted dialogue remains
                    expanded = post_process_story_text(expanded)
                    if len(expanded) >= min_chars:
                        return expanded
                    else:
                        # If LM returned shorter text, fall through to deterministic expansion
                        text = expanded
                except Exception:
                    pass
        except Exception:
            pass

        # Fallback deterministic expansion: paraphrase + add sensory details
        # Keep first-person and avoid quotes/timeline markers
        try:
            base = text.strip()
            extras = []
            # éšæ™¦çš„å¼‚å¸¸ç»†èŠ‚ - ç»†æ€ææçš„ç¢ç‰‡
            extras.append('æˆ‘è®°å¾—åº—ä¸»æ‰‹ä¸Šæœ‰ä¸ªå¾ˆæ·±çš„ç–¤ï¼Œä½†ç°åœ¨æƒ³ä¸èµ·æ¥æ˜¯å“ªåªæ‰‹ã€‚')
            extras.append('é‚£æ¡é±¼çš„çœ¼ç›...æˆ‘æ€»è§‰å¾—å®ƒåœ¨çœ‹æˆ‘ã€‚ä¸æ˜¯çœ‹é±¼ç¼¸å¤–é¢ï¼Œæ˜¯çœ‹"æˆ‘"ã€‚')
            extras.append('ä¹°é±¼çš„æ—¶å€™æˆ‘ä»˜äº†ç°é‡‘ã€‚å›å®¶æ•°é’±åŒ…å‘ç°é’±è¿˜åœ¨ã€‚')
            extras.append('æˆ‘é—®è¿‡ä¸‰ä¸ªæ‘Šä¸»ï¼Œä»–ä»¬çš„ååº”éƒ½ä¸€æ¨¡ä¸€æ ·ã€‚è¿è¯´è¯çš„è¯­æ°”éƒ½æ˜¯ã€‚')
            extras.append('å¥‡æ€ªçš„æ˜¯ï¼Œæˆ‘æ‰‹æœºé‡Œé‚£å¤©æ‹çš„ç…§ç‰‡æ—¶é—´æˆ³æœ‰é—®é¢˜ã€‚æ˜¾ç¤ºçš„æ—¶é—´æˆ‘æ ¹æœ¬ä¸åœ¨é‚£é‡Œã€‚')
            extras.append('ç°åœ¨æ¯æ¬¡ç»è¿‡é‚£æ¡è¡—ï¼Œæ€»æœ‰ç§è¢«äººç›¯ç€çš„æ„Ÿè§‰ã€‚ä½†å›å¤´ä»€ä¹ˆéƒ½æ²¡æœ‰ã€‚')
            extras.append('æœ‰æ²¡æœ‰äººçŸ¥é“...é±¼ä¼šä¸ä¼šè®°ä½ä¹°å®ƒçš„äººçš„è„¸ï¼Ÿ')

            # Compose until reaching min_chars
            expanded = base
            i = 0
            while len(expanded) < min_chars and i < len(extras):
                expanded = expanded + '\n' + extras[i]
                i += 1

            # If still short, repeat descriptive paraphrase with slight variation
            paraphrase_seed = (
                'æˆ‘è¶Šå›æƒ³è¶Šè§‰å¾—ä¸å¯¹åŠ²ï¼Œé‚£äº›ç»†èŠ‚è¿æˆä¸€æ¡çº¿ç´¢å´åˆæ–­æˆäº†ç¢ç‰‡ã€‚'
            )
            while len(expanded) < min_chars:
                expanded += '\n' + paraphrase_seed
                paraphrase_seed = paraphrase_seed.replace('è¶Š', 'æ„ˆ').replace('è§‰å¾—', 'æ„Ÿè§‰')

            # Final cleanup
            expanded = post_process_story_text(expanded)
            return expanded
        except Exception:
            return text


def generate_ai_story(category=None, location=None, persona=None):
    """Generate a complete AI-driven urban legend story

    Optional parameters allow callers to specify a category, location, or persona.
    If any parameter is None, the function falls back to a random choice.
    """
    try:
        # Random story elements
        if category is None:
            category = random.choice(LEGEND_CATEGORIES)
        if location is None:
            location = random.choice(CITY_LOCATIONS)
        if persona is None:
            persona = random.choice(AI_PERSONAS)
        
        # Generate story title and content using new prompt format
        prompt_data = generate_story_prompt(category, location, persona)
        
        # ä¼˜å…ˆä½¿ç”¨ LM Studio æœ¬åœ°æ¨¡å‹
        use_lm_studio = os.getenv('USE_LM_STUDIO', 'true').lower() == 'true'
        lm_studio_url = os.getenv('LM_STUDIO_URL', 'http://localhost:1234/v1')
        
        content = None
        title = None
        
        # å°è¯• LM Studio
        if use_lm_studio:
            try:
                print(f"[generate_ai_story] ä½¿ç”¨ LM Studio ç”Ÿæˆæ•…äº‹...")
                import subprocess
                import json
                
                # ä½¿ç”¨ curl è°ƒç”¨ LM Studioï¼ˆPython HTTP åº“ä¸ LM Studio æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
                chat_url = f"{lm_studio_url.rstrip('/v1')}/v1/chat/completions"
                
                request_data = {
                    "messages": [
                        {"role": "system", "content": prompt_data['system']},
                        {"role": "user", "content": prompt_data['prompt']}
                    ],
                    "temperature": 0.9,
                    "max_tokens": 800
                }
                
                curl_command = [
                    'curl', '-s', '-X', 'POST', chat_url,
                    '-H', 'Content-Type: application/json',
                    '-d', json.dumps(request_data, ensure_ascii=False),
                    '--max-time', '120'
                ]
                
                result = subprocess.run(
                    curl_command,
                    capture_output=True,
                    text=True,
                    timeout=120
                )
                
                if result.returncode != 0:
                    raise Exception(f"curl å‘½ä»¤å¤±è´¥: {result.stderr}")
                
                response_data = json.loads(result.stdout)
                content_raw = response_data['choices'][0]['message']['content']
                
                print(f"[generate_ai_story] åŸå§‹å†…å®¹é•¿åº¦: {len(content_raw)} å­—ç¬¦")
                
                # è¿‡æ»¤ qwen æ¨¡å‹çš„ <think> æ ‡ç­¾
                content = clean_think_tags(content_raw)
                
                print(f"[generate_ai_story] æ¸…ç†åå†…å®¹é•¿åº¦: {len(content) if content else 0} å­—ç¬¦")
                
                # æ£€æŸ¥æ¸…ç†åæ˜¯å¦æœ‰æœ‰æ•ˆå†…å®¹
                if not content or len(content) < 50:
                    print(f"[generate_ai_story] âš ï¸ æ¨¡å‹è¾“å‡ºä¸»è¦æ˜¯æ€è€ƒè¿‡ç¨‹ï¼Œå°è¯•æå–å®é™…å†…å®¹...")
                    # å°è¯•ä»åŸå§‹å†…å®¹ä¸­æå–å®é™…æ•…äº‹å†…å®¹
                    # æŸ¥æ‰¾æœ€åä¸€ä¸ª </think> ä¹‹åçš„å†…å®¹
                    if '</think>' in content_raw:
                        content = content_raw.split('</think>')[-1].strip()
                        print(f"[generate_ai_story] æå– </think> åçš„å†…å®¹: {len(content)} å­—ç¬¦")
                    
                    # å¦‚æœè¿˜æ˜¯å¤ªçŸ­ï¼Œä½¿ç”¨åŸå§‹å†…å®¹ä½†è­¦å‘Š
                    if not content or len(content) < 50:
                        content = content_raw
                        print(f"[generate_ai_story] âš ï¸ ä½¿ç”¨åŸå§‹å†…å®¹ï¼ŒåŒ…å«æ€è€ƒè¿‡ç¨‹")
                
                # ç”Ÿæˆæ ‡é¢˜ï¼ˆä½¿ç”¨æ›´ç›´æ¥çš„æç¤ºè¯é¿å…æ€è€ƒè¿‡ç¨‹ï¼‰
                title_prompt = f"æ•…äº‹ï¼š{content[:150]}\n\nè¯·ä¸ºä¸Šé¢çš„æ•…äº‹èµ·ä¸€ä¸ª5-10å­—çš„æ ‡é¢˜ï¼š"
                
                title_request = {
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯æ ‡é¢˜ç”Ÿæˆå™¨ã€‚ç”¨æˆ·ç»™ä½ æ•…äº‹ï¼Œä½ åªéœ€è¦è¾“å‡ºä¸€ä¸ªç®€çŸ­çš„æ ‡é¢˜ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å†…å®¹ã€‚"},
                        {"role": "user", "content": title_prompt}
                    ],
                    "temperature": 0.5,
                    "max_tokens": 20
                }
                
                title_curl_command = [
                    'curl', '-s', '-X', 'POST', chat_url,
                    '-H', 'Content-Type: application/json',
                    '-d', json.dumps(title_request, ensure_ascii=False),
                    '--max-time', '60'
                ]
                
                title_result = subprocess.run(
                    title_curl_command,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                
                if title_result.returncode != 0:
                    raise Exception(f"æ ‡é¢˜ç”Ÿæˆå¤±è´¥: {title_result.stderr}")
                
                title_response_data = json.loads(title_result.stdout)
                title_raw = title_response_data['choices'][0]['message']['content'].strip()
                
                # ä½¿ç”¨ç»Ÿä¸€çš„æ¸…ç†å‡½æ•°
                title = clean_think_tags(title_raw)
                
                # æ¸…ç†å¼•å·å’Œå¤šä½™å­—ç¬¦
                title = title.replace('"', '').replace('"', '').replace('"', '').replace('ã€Š', '').replace('ã€‹', '')
                title = title.strip()
                
                # å¦‚æœæ ‡é¢˜å¤ªé•¿ï¼Œå–ç¬¬ä¸€å¥è¯
                if len(title) > 20:
                    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', title)
                    title = sentences[0][:15]
                
                # å¦‚æœä»ç„¶æ²¡æœ‰æœ‰æ•ˆæ ‡é¢˜ï¼Œä»æ•…äº‹å†…å®¹ç”Ÿæˆç®€å•æ ‡é¢˜
                if not title or len(title) < 3:
                    # ä»åˆ†ç±»å’Œåœ°ç‚¹ç”Ÿæˆç®€å•æ ‡é¢˜
                    cat_names = {
                        'subway_ghost': 'åœ°é“æ€ªè°ˆ',
                        'abandoned_building': 'åºŸæ¥¼æƒŠé­‚',
                        'cursed_object': 'è¯…å’’ä¹‹ç‰©',
                        'missing_person': 'ç¦»å¥‡å¤±è¸ª',
                        'supernatural_encounter': 'çµå¼‚äº‹ä»¶'
                    }
                    title = cat_names.get(category, 'éƒ½å¸‚ä¼ è¯´')
                
                print(f"[generate_ai_story] âœ… LM Studio ç”ŸæˆæˆåŠŸ: {title}")
                
            except Exception as e:
                import traceback
                error_message = str(e)
                print(f"[generate_ai_story] âŒ LM Studio å¤±è´¥: {type(e).__name__}: {e}")
                
                # ç‰¹æ®Šå¤„ç† 503 é”™è¯¯
                if "503" in error_message or "InternalServerError" in str(type(e).__name__):
                    print("[generate_ai_story] âš ï¸ æ£€æµ‹åˆ° 503 é”™è¯¯ - å¯èƒ½çš„åŸå› :")
                    print("   1. LM Studio æ¨¡å‹æœªå®Œå…¨åŠ è½½")
                    print("   2. æœåŠ¡å™¨è´Ÿè½½è¿‡é«˜")
                    print("   3. å¹¶å‘è¯·æ±‚è¿‡å¤š")
                    print("[generate_ai_story] ğŸ’¡ è¯·åœ¨ LM Studio 'Local Server' æ ‡ç­¾ç¡®è®¤æ¨¡å‹å·²åŠ è½½")
                else:
                    print(f"[generate_ai_story] è¯¦ç»†é”™è¯¯:")
                    traceback.print_exc()
                
                content = None
                title = None
        
        # å¦‚æœ LM Studio å¤±è´¥ï¼Œå°è¯•åœ¨çº¿ API
        if not content:
            model = os.getenv('AI_MODEL', 'gpt-4-turbo-preview')
            
            if openai_client and 'gpt' in model.lower():
                print(f"[generate_ai_story] ä½¿ç”¨ OpenAI API...")
                response = openai_client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": prompt_data['system']},
                        {"role": "user", "content": prompt_data['prompt']}
                    ],
                    temperature=0.9,
                    max_tokens=800
                )
                content = response.choices[0].message.content
                
                # ç”Ÿæˆæ ‡é¢˜
                title_prompt = f"ä¸ºä»¥ä¸‹éƒ½å¸‚ä¼ è¯´æ•…äº‹ç”Ÿæˆä¸€ä¸ªç®€çŸ­ï¼ˆ6-12å­—ï¼‰ã€å¸å¼•äººã€ç•¥å¸¦æ‚¬ç–‘çš„è´´æ–‡æ ‡é¢˜ã€‚ä¸è¦åŠ å¼•å·ã€‚\n\n{content[:200]}"
                title_response = openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": title_prompt}],
                    temperature=0.7,
                    max_tokens=20
                )
                title = title_response.choices[0].message.content.strip().replace('"', '').replace('"', '').replace('"', '')
                
            elif anthropic_client:
                print(f"[generate_ai_story] ä½¿ç”¨ Anthropic API...")
                response = anthropic_client.messages.create(
                    model=model,
                    max_tokens=800,
                    messages=[
                        {"role": "user", "content": f"{prompt_data['system']}\n\n{prompt_data['prompt']}"}
                    ]
                )
                content = response.content[0].text
                
                # ç”Ÿæˆæ ‡é¢˜
                title_prompt = f"ä¸ºä»¥ä¸‹éƒ½å¸‚ä¼ è¯´æ•…äº‹ç”Ÿæˆä¸€ä¸ªç®€çŸ­ï¼ˆ5-10å­—ï¼‰ã€å¸å¼•äººã€ç•¥å¸¦æ‚¬ç–‘çš„æ ‡é¢˜ã€‚ä¸è¦åŠ å¼•å·ã€‚\n\n{content[:200]}"
                title_response = anthropic_client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=20,
                    messages=[{"role": "user", "content": title_prompt}]
                )
                title = title_response.content[0].text.strip()
            else:
                print(f"[generate_ai_story] âŒ æ²¡æœ‰å¯ç”¨çš„ AI æœåŠ¡")
                return None
        
        if not content or not title:
            return None

        # Post-process title and content to enforce user constraints
        try:
            processed_content = post_process_story_text(content)
        except Exception:
            processed_content = content

        # If the fish-tank horror story is too short, attempt to expand it
        try:
            if category == 'fish_tank_horror':
                processed_content = expand_story_for_category(processed_content, category, min_chars=350)
        except Exception:
            pass

        try:
            processed_title = post_process_story_text(title)
            # Titles should be short: truncate if too long
            if processed_title and len(processed_title) > 24:
                processed_title = processed_title.split('\n', 1)[0][:20]
            
            # Add title tag (ã€æ±‚åŠ©ã€‘or ã€åˆ†äº«ã€‘for new stories)
            processed_title = add_title_tag(processed_title, story_age_days=0)
        except Exception:
            processed_title = title
            # Still try to add tag even if processing failed
            try:
                processed_title = add_title_tag(processed_title, story_age_days=0)
            except Exception:
                pass

        # ğŸ” æ£€æŸ¥å»é‡ï¼šé¿å…ç”Ÿæˆç›¸ä¼¼æˆ–é‡å¤çš„æ•…äº‹
        if not check_story_similarity(processed_title, processed_content, category):
            print(f"[generate_ai_story] âš ï¸  æ•…äº‹ä¸æœ€è¿‘å†…å®¹è¿‡äºç›¸ä¼¼ï¼Œé‡æ–°å°è¯•...")
            # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œscheduler_tasks ä¼šé‡è¯•ç”Ÿæˆ
            return None

        return {
            'title': processed_title,
            'content': processed_content,
            'category': category,
            'location': location,
            'ai_persona': generate_realistic_username_for_ai(),  # ä½¿ç”¨çœŸå®ç”¨æˆ·å
            'persona_style': persona['style']
        }
        
    except Exception as e:
        print(f"Error generating AI story: {e}")
        return None

def generate_realistic_username_for_ai():
    """ä¸ºAIæ¥¼ä¸»ç”ŸæˆçœŸå®çš„ç”¨æˆ·åï¼ˆä¸app.pyä¸­çš„å‡½æ•°ç‹¬ç«‹ï¼Œæ›´ç½‘ç»œåŒ–é£æ ¼ï¼‰"""
    import random
    prefixes = [
        'å¤œè¡Œ', 'å­¤ç‹¬', 'å¯‚é™', 'æµæµª', 'è¿·å¤±', 'è¿½å¯»', 'æ²‰é»˜', 'ç ´æ™“', 'æš®è‰²', 'æ˜Ÿç©º',
        'éƒ½å¸‚', 'åˆå¤œ', 'æ·±å¤œ', 'å‡Œæ™¨', 'é»„æ˜', 'æœˆå…‰', 'å½±å­', 'å¹½çµ', 'æ¼‚æ³Š', 'å®ˆæœ›',
        'æ—§äº‹', 'å›å¿†', 'æ•…äºº', 'é™Œç”Ÿ', 'åŒ¿å', 'è¿‡å®¢', 'å¬é£', 'çœ‹é›¨', 'ç­‰å¾…', 'å¯»è§…'
    ]
    
    suffixes = [
        'è€…', 'äºº', 'å®¢', 'ä¾ ', 'çŒ«', 'ç‹—', 'é¸Ÿ', 'é±¼', 'é¾™', 'å‡¤',
        'å°‘å¹´', 'é’å¹´', 'æ—…äºº', 'è¿‡å®¢', 'æµªäºº', 'æ¸¸å­', 'è¡Œè€…'
    ]
    
    # ç”Ÿæˆæ›´ç½‘ç»œåŒ–çš„ç”¨æˆ·å
    style = random.randint(1, 5)
    
    if style == 1:
        # å‰ç¼€ + ä¸‹åˆ’çº¿ + æ•°å­— (ä¾‹: å¤œè¡Œ_2024)
        return f"{random.choice(prefixes)}_{random.randint(2020, 2024)}"
    elif style == 2:
        # å‰ç¼€ + æ•°å­— + åç¼€ (ä¾‹: å­¤ç‹¬666è€…)
        return f"{random.choice(prefixes)}{random.choice(['520', '666', '888', '999', '123'])}{random.choice(suffixes)}"
    elif style == 3:
        # å‰ç¼€ + åç¼€ + æ•°å­— (ä¾‹: æµæµªå®¢2023)
        return f"{random.choice(prefixes)}{random.choice(suffixes)}{random.randint(10, 9999)}"
    elif style == 4:
        # å‰ç¼€ + æ•°å­— (ä¾‹: å‡Œæ™¨3619)
        return f"{random.choice(prefixes)}{random.randint(100, 9999)}"
    else:
        # å‰ç¼€ + ç‚¹ + åç¼€ (ä¾‹: æœˆå…‰.è¡Œè€…)
        return f"{random.choice(prefixes)}.{random.choice(suffixes)}"

def generate_evidence_image(story_id, story_title, story_content, comment_context=""):
    """Generate horror-themed evidence image using Stable Diffusion
    
    Args:
        story_id: æ•…äº‹IDï¼Œç”¨äºç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
        story_title: æ•…äº‹æ ‡é¢˜
        story_content: æ•…äº‹å†…å®¹
        comment_context: ç”¨æˆ·è¯„è®ºä¸Šä¸‹æ–‡
    
    Returns:
        list: ç”Ÿæˆçš„æ‰€æœ‰å›¾ç‰‡è·¯å¾„åˆ—è¡¨ [(æ¨¡æ¿ç±»å‹, æ–‡ä»¶è·¯å¾„), ...]
    """
    try:
        import os
        use_real_ai = os.getenv('USE_DIFFUSER_IMAGE', 'true').lower() == 'true'
        
        if use_real_ai:
            print(f"[generate_evidence_image] ä½¿ç”¨ Stable Diffusion ç”Ÿæˆå›¾ç‰‡...")
            
            try:
                from diffusers import StableDiffusionPipeline
                import torch
                from PIL import Image, ImageFilter, ImageEnhance
                import random
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ¨¡å‹
                model_id = os.getenv('DIFFUSION_MODEL', 'runwayml/stable-diffusion-v1-5')
                
                # æ™ºèƒ½åˆ†ææ•…äº‹å†…å®¹ + è¯„è®ºå†…å®¹ï¼Œç”Ÿæˆä¸æ•…äº‹ç›´æ¥ç›¸å…³çš„çœŸå®åœºæ™¯
                story_text = (story_title + " " + story_content[:300]).lower()
                # åŠ å…¥è¯„è®ºå’Œè´´æ–‡çš„å…³é”®è¯ - æƒé‡æ›´é«˜
                comment_text = ""
                if comment_context:
                    comment_text = comment_context.lower()
                    story_text += " " + comment_text
                
                print(f"[generate_evidence_image] åˆ†ææ•…äº‹: {story_text[:150]}...")
                if comment_text:
                    print(f"[generate_evidence_image] è¯„è®ºçº¿ç´¢: {comment_text[:100]}...")
                
                # ä»æ•…äº‹ä¸­æå–å…³é”®åœºæ™¯å…ƒç´ ï¼ˆåŒ…æ‹¬è¯„è®ºä¸­çš„å…³é”®è¯ï¼‰
                scene_keywords = {
                    # åœ°é“ç›¸å…³ - ä¼˜å…ˆçº§æœ€é«˜ï¼Œå› ä¸ºè¿™ä¸ªåœºæ™¯æœ€å…·ä½“
                    'subway': {
                        'scenes': ['subway train interior with empty seats', 'subway station platform', 'metro train car at night'],
                        'details': ['æ±½è½¦ç¯å½±ã€æœˆå°ç©ºè¡ã€è½¦å¢è¯¡å¼‚', '13å·è½¦å¢ã€è½¦å·æ˜¾ç¤ºå±ã€æœˆå°ç”µå­é’Ÿ']
                    },
                    'åœ°é“': {
                        'scenes': ['subway train interior with empty seats', 'subway station platform at night', 'metro corridor'],
                        'details': ['åœ°é“å†…éƒ¨ã€ä¹˜å®¢ã€è¯¡å¼‚']
                    },
                    'è½¦å¢': {
                        'scenes': ['train car interior, seats and handrails', 'empty subway carriage at night'],
                        'details': ['è½¦å¢å†…éƒ¨ã€åº§ä½ã€å¯‚é™']
                    },
                    
                    # é•œå­ç›¸å…³
                    'mirror': {
                        'scenes': ['bathroom with mirror and sink', 'bedroom mirror on dresser', 'mirror reflection at night'],
                        'details': ['é•œå­å€’å½±ã€è¯¡å¼‚è¡¨æƒ…']
                    },
                    'é•œå­': {
                        'scenes': ['bathroom mirror above sink, faucet visible', 'bedroom mirror with dresser'],
                        'details': ['é•œä¸­å€’å½±ä¸æ˜¯è‡ªå·±ã€è¯¡å¼‚ç¬‘å®¹']
                    },
                    'å€’å½±': {
                        'scenes': ['mirror reflection, distorted face', 'window reflection at night'],
                        'details': ['å€’å½±ã€éæœ¬äººã€è¯¡å¼‚']
                    },
                    
                    # é—¨ç›¸å…³  
                    'door': {
                        'scenes': ['apartment door with peephole and handle', 'residential hallway with doors'],
                        'details': ['æ•²é—¨ã€é—¨å·ã€è¯¡å¼‚']
                    },
                    'é—¨': {
                        'scenes': ['apartment door, door handle, peephole', 'residential building hallway'],
                        'details': ['é—¨ã€çŒ«çœ¼ã€æ•²é—¨å£°']
                    },
                    'æ•²é—¨': {
                        'scenes': ['apartment entrance door closeup', 'door with door number plate at night'],
                        'details': ['æœ‰äººæ•²é—¨ã€é—¨å·ã€æ—¶é—´']
                    },
                    
                    # æ¥¼é“ç›¸å…³
                    'hallway': {
                        'scenes': ['apartment building corridor', 'residential stairwell'],
                        'details': ['æ¥¼é“ã€èµ°å»Šã€æ˜æš—']
                    },
                    'èµ°å»Š': {
                        'scenes': ['apartment building hallway with doors', 'residential corridor with lighting'],
                        'details': ['èµ°å»Šã€ç¯å…‰ã€è„šæ­¥å£°']
                    },
                    'æ¥¼é“': {
                        'scenes': ['apartment stairwell, concrete steps', 'building corridor with elevator'],
                        'details': ['æ¥¼æ¢¯ã€ç”µæ¢¯ã€è¯¡å¼‚']
                    },
                    'æ¥¼æ¢¯': {
                        'scenes': ['residential building staircase, handrails', 'stairwell in apartment building at night'],
                        'details': ['é˜¶æ¢¯ã€ç¯å…‰ã€è„šæ­¥']
                    },
                    
                    # çª—æˆ·ç›¸å…³
                    'window': {
                        'scenes': ['apartment window view at night', 'window with curtains'],
                        'details': ['çª—å¤–ã€æœˆäº®ã€äººå½±']
                    },
                    'çª—': {
                        'scenes': ['residential window from inside', 'apartment window at night'],
                        'details': ['çª—å¤–ã€è¯¡å¼‚ã€äººå½±']
                    },
                    'çª—å¤–': {
                        'scenes': ['window view from apartment at night', 'dark window with city lights'],
                        'details': ['çª—å¤–æ™¯è±¡ã€è¯¡å¼‚ã€æœˆå…‰']
                    },
                    
                    # æˆ¿é—´ç›¸å…³
                    'å§å®¤': {
                        'scenes': ['bedroom interior, bed and furniture', 'residential bedroom at night'],
                        'details': ['å§å®¤ã€åºŠã€æ˜æš—']
                    },
                    'æˆ¿é—´': {
                        'scenes': ['residential room interior at night', 'apartment bedroom'],
                        'details': ['æˆ¿é—´ã€è¯¡å¼‚ã€é˜´å½±']
                    },
                    'åºŠ': {
                        'scenes': ['bedroom bed under dim light', 'bed with sheets and pillows'],
                        'details': ['åºŠã€ç¡çœ ã€è¯¡å¼‚']
                    },
                    
                    # å…¶ä»–è¯¡å¼‚åœºæ™¯
                    'æ‰‹æœº': {
                        'scenes': ['smartphone screen in dark', 'phone screen in hand'],
                        'details': ['å±å¹•ã€æ‹ç…§ã€è¯æ®']
                    },
                    'ç…§ç‰‡': {
                        'scenes': ['photograph on table', 'old photo or polaroid'],
                        'details': ['ç…§ç‰‡ã€è¯æ®ã€è¯¡å¼‚']
                    },
                    'å½•éŸ³': {
                        'scenes': ['phone recording screen', 'audio device'],
                        'details': ['å½•éŸ³ã€è¯­éŸ³ã€è¯æ®']
                    },
                    'ç¬”è®°': {
                        'scenes': ['handwritten note on paper', 'notebook page with writing'],
                        'details': ['ç¬”è®°ã€æ–‡å­—ã€çº¿ç´¢']
                    },
                    'æ—¶é—´': {
                        'scenes': ['clock showing strange time', 'digital display at night'],
                        'details': ['æ—¶é—´ã€è¯¡å¼‚æ•°å­—ã€ä¸å¯»å¸¸']
                    },
                    
                    # è¯¡å¼‚æ°›å›´
                    'å½±å­': {
                        'scenes': ['shadow on wall in dark', 'mysterious shadow in room'],
                        'details': ['å½±å­ã€äººå½±ã€è¯¡å¼‚']
                    },
                    'è„šæ­¥': {
                        'scenes': ['empty hallway floor', 'stairwell steps at night'],
                        'details': ['åœ°é¢ã€è„šæ­¥å£°ã€è¯¡å¼‚']
                    },
                    'å£°éŸ³': {
                        'scenes': ['empty room interior at night', 'residential space interior'],
                        'details': ['æˆ¿é—´å†…ã€å£°éŸ³ã€è¯¡å¼‚']
                    },
                    'å†·': {
                        'scenes': ['cold apartment interior', 'frost on window'],
                        'details': ['å¯’å†·ã€å†»æ°”ã€è¯¡å¼‚']
                    },
                    'è¯¡å¼‚': {
                        'scenes': ['dimly lit urban apartment', 'creepy residential space'],
                        'details': ['è¯¡å¼‚ã€é˜´å½±ã€ä¸å¯»å¸¸']
                    },
                }
                
                # å¤šå±‚çº§åŒ¹é…åœºæ™¯æè¿° - ä¼˜å…ˆåŒ¹é…è¯„è®ºä¸­çš„å…³é”®è¯
                scene_desc = None
                scene_details = ""
                matched_keyword = None
                
                # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šåŒ¹é…è¯„è®ºä¸­çš„å…³é”®è¯ï¼ˆç”¨æˆ·è¡¥å……çš„ä¿¡æ¯ï¼‰
                if comment_text:
                    for keyword, scene_data in scene_keywords.items():
                        if keyword in comment_text:
                            scene_desc = random.choice(scene_data.get('scenes', ['dimly lit apartment']))
                            scene_details = random.choice(scene_data.get('details', ['']))
                            matched_keyword = keyword
                            print(f"[generate_evidence_image] ä»è¯„è®ºåŒ¹é…: {keyword} -> {scene_desc}")
                            break
                
                # ç¬¬äºŒä¼˜å…ˆçº§ï¼šåŒ¹é…æ•…äº‹æ ‡é¢˜å’Œå†…å®¹
                if not scene_desc:
                    for keyword, scene_data in scene_keywords.items():
                        if keyword in story_text:
                            scene_desc = random.choice(scene_data.get('scenes', ['dimly lit apartment']))
                            scene_details = random.choice(scene_data.get('details', ['']))
                            matched_keyword = keyword
                            print(f"[generate_evidence_image] ä»æ•…äº‹åŒ¹é…: {keyword} -> {scene_desc}")
                            break
                
                # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œä½¿ç”¨é€šç”¨åœºæ™¯
                if not scene_desc:
                    scene_desc = 'dimly lit urban apartment interior, everyday furniture'
                    scene_details = 'è¯¡å¼‚ã€ä¸å¯»å¸¸çš„æ°›å›´'
                    print(f"[generate_evidence_image] ä½¿ç”¨é»˜è®¤åœºæ™¯")
                
                # çºªå®ç…§ç‰‡é£æ ¼çš„ prompt - çœŸå®åœºæ™¯ä¸­èå…¥æ•…äº‹ç‰¹å®šçš„è¯¡å¼‚å…ƒç´ 
                # æå–æ˜¾æ€§ç»†èŠ‚ï¼ˆå¼•å·å†…çŸ­è¯­ã€æ•°å­—ç¼–å·ã€æ—¶é—´ã€åœ°ç‚¹å…³é”®è¯ï¼‰ï¼Œå¹¶æŠŠå®ƒä»¬ç›´æ¥åŠ å…¥åˆ° prompt
                explicit_details = []
                # ä»åŸå§‹æ•…äº‹/è¯„è®ºæ–‡æœ¬ä¸­æå–å¼•å·å†…çŸ­è¯­
                try:
                    quoted = re.findall(r'â€œ([^â€]+)â€|"([^"]+)"|â€˜([^â€™]+)â€™|\'([^\']+)\'', story_text)
                    for tup in quoted:
                        for part in tup:
                            if part:
                                explicit_details.append(part)
                except Exception:
                    pass

                # æå–å¸¸è§çš„æ•°å­—+å•ä½ï¼ˆå¦‚ 13å·ã€3å±‚ã€3ç‚¹ç­‰ï¼‰å’Œæ—¶é—´æ ¼å¼
                try:
                    nums = re.findall(r"\d+[å·èŠ‚å±‚æ¥¼ç‚¹åˆ†é’Ÿåˆ†ç§’]?", story_text)
                    explicit_details.extend(nums)
                except Exception:
                    pass

                # æ·»åŠ  title ä»¥å¢å¼ºæç¤ºçš„è¯­ä¹‰ç›¸å…³æ€§
                if isinstance(story_title, str) and story_title.strip():
                    explicit_details.append(story_title.strip())

                # å»é‡å¹¶é™åˆ¶æ•°é‡
                seen = set()
                filtered_details = []
                for d in explicit_details:
                    dd = d.strip()
                    if not dd:
                        continue
                    if dd in seen:
                        continue
                    seen.add(dd)
                    filtered_details.append(dd)
                    if len(filtered_details) >= 6:
                        break
                explicit_details_text = ", ".join(filtered_details)

                # å°†æ˜¾æ€§ç»†èŠ‚æ˜ å°„ä¸ºæ›´æ˜ç¡®çš„è§†è§‰çŸ­è¯­ï¼ˆä¸­æ–‡->è‹±æ–‡è§†è§‰æè¿°ï¼‰ä»¥æé«˜å›¾åƒçš„å¼ºå…³è”æ€§
                visual_map = {
                    # åœ°ç‚¹ / æ ‡é¢˜ç›¸å…³
                    'é‡‘é±¼è¡—æ–—é±¼': 'fish tank in small pet shop, visible aquariums and signage',
                    'åœ°é“': 'subway interior or platform, visible carriage number display',
                    '13å·': 'carriage number 13 on digital display',
                    '13å·è½¦å¢': 'train carriage labeled 13 on display',
                    'åœ°é“2å·çº¿': 'metro line 2 signage, platform signs',
                    # å£°éŸ³ç›¸å…³ï¼ˆè½¬æ¢ä¸ºå¯è§†çº¿ç´¢ï¼Œå¦‚æ°´æ³¢ã€ç»ç’ƒæŒ¯åŠ¨ç­‰ï¼‰
                    'ç °ç °å£°': 'water ripple marks on aquarium glass, visible impact ripples',
                    'æ•²é±¼ç¼¸': 'closeup of aquarium glass with impact marks, chipped paint',
                    'æ•²é—¨': 'door with knock marks and peephole, nighttime hallway',
                    'è„šæ­¥å£°': 'scuffed floor and footprints in dim hallway',
                    'å£°éŸ³': 'sound source implied by movement in curtains or ripples on water',
                    'å£°å“': 'vibrations or visible disturbance on surfaces',
                    'å‡Œæ™¨3ç‚¹': 'digital clock showing 03:00, dark night lighting',
                    '3ç‚¹': 'digital clock showing 03:00',
                    'é•œå­': 'bathroom mirror with faint reflection, smudge or handprint',
                    'å€’å½±': 'reflection in glass showing a different face',
                    'é±¼ç¼¸': 'fish tank with visible water, algae, and glass reflections',
                    'ç…§ç‰‡': 'polaroid-style photograph laying on a table',
                    'å½•éŸ³': 'phone recording screen or audio recorder device visible',
                    'çª—å¤–': 'view through window with streetlights or moonlight',
                    'é—¨': 'apartment door with visible handle and peephole',
                }

                visual_phrases = []
                for d in filtered_details:
                    key = d
                    # ç®€å•å½’ä¸€åŒ–æ•°è¯ï¼Œä¾‹å¦‚å«æ•°å­—çš„çŸ­è¯­
                    if any(ch.isdigit() for ch in key) and key not in visual_map:
                        # map '13å·' -> 'number 13 signage'
                        visual_phrases.append(f"signage or digits: {key}")
                        continue
                    mapped = visual_map.get(key)
                    if mapped:
                        visual_phrases.append(mapped)
                    else:
                        # è¯•ç€æŠŠä¸­æ–‡çŸ­è¯­åŸæ ·æ”¾å…¥ï¼Œä½†è½¬æ¢æˆæç¤ºå‹å¥½çš„å½¢å¼
                        visual_phrases.append(f"visual cue: {key}")

                visual_phrases_text = ", ".join(visual_phrases)

                # å…³é”®ï¼šå°†æ˜¾æ€§è§†è§‰çŸ­è¯­æ”¾åœ¨ prompt ä¸­çš„æ˜¾è‘—ä½ç½®ï¼Œä¾¿äºç”Ÿæˆä¸æ­£æ–‡ç´§å¯†ç›¸å…³çš„å›¾åƒ
                extra_section = ""
                if visual_phrases_text:
                    extra_section = f", include visual elements: {visual_phrases_text}"
                    if explicit_details_text:
                        extra_section += f" (keywords: {explicit_details_text})"

                prompt = (
                    f"realistic photograph, {scene_desc}, "
                    f"taken with smartphone camera at night, "
                    f"low light conditions, grainy image quality, "
                    f"slightly unfocused, amateur photography, "
                    f"real world scene, photographic evidence style, "
                    f"visible details and textures, concrete objects, "
                    f"documentary photo aesthetic, "
                    f"{scene_details}, "
                    f"subtle creepy atmosphere, barely visible face in shadow, "
                    f"inexplicable shadow, eerie presence, "
                    f"something unsettling about this place, hidden disturbing details"
                    f"{extra_section}"
                )
                
                # è´Ÿé¢æç¤ºè¯ - é¿å…å¤ªæ‰­æ›²/å¤ªæŠ½è±¡ï¼Œä½†ä¿ç•™å¾®å¦™ææ€–
                negative_prompt = (
                    "abstract, artistic, illustration, painting, drawing, sketch, "
                    "cartoon, anime, 3d render, cgi, digital art, "
                    "extremely distorted, heavily warped, grotesque, monstrous, "
                    "obvious demon, obvious ghost, obvious supernatural creature, "
                    "repetitive patterns, geometric shapes, abstract forms, "
                    "professional studio photography, dramatic lighting, cinematic, "
                    "motion blur, artistic blur, tilt-shift, "
                    "text, watermarks, signatures, "
                    "completely dark, pitch black, completely invisible, "
                    "overly bright, blown out highlights"
                )
                
                print(f"[generate_evidence_image] Prompt: {prompt[:100]}...")
                
                # ä½¿ç”¨è¾ƒå°çš„å›¾ç‰‡å°ºå¯¸åŠ å¿«ç”Ÿæˆ
                pipe = StableDiffusionPipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                    safety_checker=None,  # ç¦ç”¨å®‰å…¨æ£€æŸ¥ä»¥å…è®¸ææ€–å†…å®¹
                    requires_safety_checker=False
                )
                
                # å¦‚æœæœ‰GPUåˆ™ä½¿ç”¨GPU
                if torch.cuda.is_available():
                    pipe = pipe.to("cuda")
                    print("[generate_evidence_image] âœ… ä½¿ç”¨GPUåŠ é€Ÿ")
                    num_steps = 25
                    img_size = 512  # GPUå¯ä»¥ç›´æ¥ç”Ÿæˆ512x512
                else:
                    print("[generate_evidence_image] âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUç”Ÿæˆ")
                    # CPUæ¨¡å¼ï¼šç”Ÿæˆ512x512æ­£æ–¹å½¢å›¾ç‰‡ï¼Œé¿å…æ‹‰ä¼¸å˜å½¢
                    num_steps = 20  # æ›´å¤šæ­¥æ•°ç¡®ä¿è´¨é‡
                    img_size = 512  # ç›´æ¥ç”Ÿæˆ512x512ï¼Œæ— éœ€æ”¾å¤§
                
                # ç”Ÿæˆå›¾ç‰‡ - åªç”Ÿæˆä¸€å¼ primaryæ¨¡æ¿ä»¥èŠ‚çœCPU/å†…å­˜
                templates = []
                # åªä½¿ç”¨ primary åŸºç¡€ promptï¼ˆä¸å†ç”Ÿæˆ closeup å’Œ sourceï¼‰
                templates.append(('primary', prompt))

                # ç”Ÿæˆå¹¶ä¿å­˜å›¾ç‰‡ï¼Œæ–‡ä»¶ååŒ…å« story_id
                timestamp_base = datetime.now().strftime('%Y%m%d_%H%M%S')
                saved_files = []
                for idx, (suffix, p) in enumerate(templates):
                    print(f"[generate_evidence_image] ç”Ÿæˆæ¨¡æ¿[{suffix}] Prompt: {p[:120]}...")
                    image = pipe(
                        p,
                        negative_prompt=negative_prompt,
                        num_inference_steps=num_steps,
                        guidance_scale=8.5,
                        height=img_size,
                        width=img_size
                    ).images[0]

                    # ç¡®ä¿è¾“å‡ºæ˜¯512x512
                    if image.size != (512, 512):
                        image = image.resize((512, 512), Image.Resampling.LANCZOS)

                    # åå¤„ç†ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰
                    from PIL import ImageEnhance, ImageDraw, ImageFont
                    enhancer = ImageEnhance.Color(image)
                    image = enhancer.enhance(0.85)
                    enhancer = ImageEnhance.Brightness(image)
                    image = enhancer.enhance(0.85)
                    enhancer = ImageEnhance.Contrast(image)
                    image = enhancer.enhance(1.15)
                    enhancer = ImageEnhance.Sharpness(image)
                    image = enhancer.enhance(1.1)

                    import numpy as np
                    img_array = np.array(image)
                    noise = np.random.normal(0, 3, img_array.shape)
                    img_array = np.clip(img_array + noise, 0, 255).astype(np.uint8)
                    image = Image.fromarray(img_array)

                    draw = ImageDraw.Draw(image)
                    days_ago = random.randint(1, 30)
                    fake_date = datetime.now() - timedelta(days=days_ago)
                    timestamp_text = fake_date.strftime('%Y/%m/%d %H:%M:%S')
                    try:
                        draw.text((340, 480), timestamp_text, fill=(220, 220, 220))
                        draw.text((10, 10), f"REC â—", fill=(200, 0, 0))
                    except:
                        pass

                    # æ–‡ä»¶ååŒ…å« story_id ç¡®ä¿æ¯ä¸ªå¸–å­çš„å›¾ç‰‡æ˜¯å”¯ä¸€çš„
                    filename = f"evidence_story{story_id}_{timestamp_base}_{suffix}.png"
                    filepath = f"static/generated/{filename}"
                    image.save(filepath)
                    saved_files.append((suffix, f"/static/generated/{filename}"))
                    print(f"[generate_evidence_image] âœ… Stable Diffusion å›¾ç‰‡å·²ç”Ÿæˆ: {filepath}")

                # è¿”å›æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
                return saved_files
                
            except Exception as sd_error:
                print(f"[generate_evidence_image] Stable Diffusion å¤±è´¥: {sd_error}")
                print(f"[generate_evidence_image] å›é€€åˆ°å ä½ç¬¦å›¾ç‰‡...")
                # å›é€€åˆ°å ä½ç¬¦
                use_real_ai = False
        
        if not use_real_ai:
            # å ä½ç¬¦ç‰ˆæœ¬ - ç”Ÿæˆä¼ªçºªå®é£æ ¼çš„æ¨¡æ‹Ÿç…§ç‰‡
            print(f"[generate_evidence_image] ä½¿ç”¨å ä½ç¬¦å›¾ç‰‡ï¼ˆä¼ªçºªå®é£æ ¼ï¼‰")
            from PIL import Image, ImageDraw, ImageFilter, ImageEnhance
            import random
            import numpy as np
            
            # åˆ›å»ºå¸¦æœ‰æ¸å˜çš„æš—è‰²èƒŒæ™¯ï¼ˆæ¨¡æ‹Ÿä½å…‰ç¯å¢ƒï¼‰
            img = Image.new('RGB', (512, 512), color=(30, 32, 35))
            draw = ImageDraw.Draw(img)
            
            # æ ¹æ®æ•…äº‹ç±»å‹æ·»åŠ å…·è±¡çš„ç®€å•å‡ ä½•å›¾å½¢ï¼ˆæ¨¡æ‹Ÿå…·ä½“åœºæ™¯ï¼‰
            if 'åœ°é“' in story_title or 'è½¦å¢' in story_title:
                # æ¨¡æ‹Ÿåœ°é“è½¦å¢å†…éƒ¨ï¼šåº§æ¤…ã€æ‰¶æ‰‹
                draw.rectangle([50, 300, 150, 450], fill=(40, 42, 45))  # åº§æ¤…
                draw.rectangle([350, 300, 450, 450], fill=(38, 40, 43))  # åº§æ¤…
                draw.line([(256, 0), (256, 200)], fill=(60, 60, 60), width=5)  # æ‰¶æ‰‹æ†
            elif 'é•œå­' in story_title:
                # æ¨¡æ‹Ÿé•œå­å’Œæ´—æ‰‹å°
                draw.rectangle([100, 100, 400, 400], fill=(45, 48, 52))  # é•œå­æ¡†
                draw.rectangle([150, 350, 350, 450], fill=(55, 55, 58))  # æ´—æ‰‹å°
            elif 'é—¨' in story_title or 'æ¥¼é“' in story_title:
                # æ¨¡æ‹Ÿé—¨å’Œèµ°å»Š
                draw.rectangle([180, 50, 330, 480], fill=(50, 45, 40))  # é—¨
                draw.ellipse([235, 240, 275, 280], fill=(70, 70, 70))  # é—¨æŠŠæ‰‹
                draw.rectangle([10, 100, 100, 150], fill=(60, 55, 50))  # å¢™ä¸Šçš„ä¸œè¥¿
            else:
                # é»˜è®¤ï¼šæˆ¿é—´å†…éƒ¨ç‰©å“
                draw.rectangle([80, 250, 200, 450], fill=(45, 43, 40))  # å®¶å…·
                draw.rectangle([320, 200, 450, 400], fill=(42, 40, 38))  # å®¶å…·
                draw.line([(0, 380), (512, 380)], fill=(35, 33, 30), width=3)  # åœ°æ¿çº¿
            
            # æ·»åŠ ç»†å¾®å™ªç‚¹ï¼ˆæ¨¡æ‹Ÿèƒ¶ç‰‡é¢—ç²’ï¼‰
            pixels = img.load()
            for i in range(0, 512, 2):  # è·³æ ¼å¤„ç†ä»¥åŠ å¿«é€Ÿåº¦
                for j in range(0, 512, 2):
                    noise = random.randint(-8, 8)
                    r, g, b = pixels[i, j]
                    pixels[i, j] = (
                        max(0, min(255, r + noise)),
                        max(0, min(255, g + noise)),
                        max(0, min(255, b + noise + 2))  # è½»å¾®çš„è“è‰²åç§»
                    )
            
            # åº”ç”¨æ¨¡ç³Šï¼ˆæ¨¡æ‹Ÿå¯¹ç„¦ä¸å‡†/æ‰‹æŠ–ï¼‰
            img = img.filter(ImageFilter.GaussianBlur(radius=1.5))
            
            # é™ä½é¥±å’Œåº¦
            enhancer = ImageEnhance.Color(img)
            img = enhancer.enhance(0.5)
            
            # æ·»åŠ ç›‘æ§å½•åƒé£æ ¼çš„æ—¶é—´æˆ³
            draw = ImageDraw.Draw(img)
            days_ago = random.randint(1, 30)
            fake_date = datetime.now() - timedelta(days=days_ago)
            timestamp_text = fake_date.strftime('%Y/%m/%d %H:%M:%S')
            
            try:
                # å³ä¸‹è§’æ—¶é—´æˆ³ï¼ˆç™½è‰²åŠé€æ˜ï¼‰
                draw.text((340, 480), timestamp_text, fill=(200, 200, 200))
                # å·¦ä¸Šè§’RECæ ‡è®°
                draw.text((10, 10), f"REC â—", fill=(180, 0, 0))
                # æ·»åŠ ä¸€äº›æ¨¡æ‹Ÿçš„æ‰«æçº¿
                for y in range(0, 512, 8):
                    draw.line([(0, y), (512, y)], fill=(255, 255, 255), width=1)
                    img_array = np.array(img)
                    img_array[y, :] = np.clip(img_array[y, :] * 0.95, 0, 255)
                    img = Image.fromarray(img_array.astype(np.uint8))
            except:
                pass
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            # å ä½ç¬¦æ–‡ä»¶åä¹ŸåŒ…å« story_id
            filename = f"evidence_story{story_id}_{timestamp}_placeholder.png"
            filepath = f"static/generated/{filename}"
            img.save(filepath)
            
            # è¿”å›åˆ—è¡¨æ ¼å¼ä»¥ä¿æŒä¸€è‡´æ€§
            return [('placeholder', f"/static/generated/{filename}")]
        
    except Exception as e:
        print(f"[generate_evidence_image] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return []

def generate_audio_description_with_lm_studio(title, content, comment_context=""):
    """ä½¿ç”¨ LM Studio ç”Ÿæˆä¸°å¯Œçš„éŸ³é¢‘åœºæ™¯æè¿°ï¼Œå¢åŠ å¤šæ ·æ€§"""
    try:
        import subprocess
        import json
        
        lm_studio_url = os.getenv('LM_STUDIO_URL', 'http://localhost:1234/v1')
        
        # æ„é€  promptï¼Œè®© AI æ ¹æ®æ•…äº‹ç”ŸæˆéŸ³é¢‘åœºæ™¯æè¿°
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªéŸ³é¢‘åœºæ™¯ä¸“å®¶ã€‚æ ¹æ®ç»™å®šçš„æ•…äº‹å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„ã€ç”ŸåŠ¨çš„éŸ³é¢‘ç¯å¢ƒæè¿°ã€‚
        
æè¿°åº”è¯¥åŒ…æ‹¬:
1. ä¸»è¦çš„å£°éŸ³å…ƒç´  (1-2 ä¸ª)
2. å£°éŸ³çš„ç‰¹å¾ (æ€¥ä¿ƒ/ç¼“æ…¢/é‡å¤/å˜åŒ–ç­‰)
3. æ€»ä½“çš„æƒ…ç»ªæ°›å›´

è¿”å›æ ¼å¼: å•è¡Œæ–‡æœ¬ï¼Œä¸è¶…è¿‡ 100 å­—

ç¤ºä¾‹:
"åœ°ä¸‹éš§é“ä¸­çš„ç©ºæ´å›å£°ï¼Œä¼´éšç€è§„å¾‹çš„æ•²å‡»å£°ï¼ŒèŠ‚å¥è¯¡å¼‚ï¼Œä»¤äººä¸å®‰"
"å¾®å¼±çš„äººç±»å‘¼å¸å£°æ··åˆç€ä½é¢‘å—¡é¸£ï¼Œåƒæœ‰æ— å½¢çš„ä¸œè¥¿åœ¨èº«è¾¹"
"""

        user_prompt = f"""æ•…äº‹æ ‡é¢˜: {title}

æ•…äº‹å†…å®¹: {content[:200]}

ç”¨æˆ·è¯„è®º: {comment_context[:150]}

è¯·ç”Ÿæˆè¿™ä¸ªæ•…äº‹å¯¹åº”çš„éŸ³é¢‘åœºæ™¯æè¿°ã€‚"""

        # ä½¿ç”¨ curl è°ƒç”¨ LM Studio
        curl_command = [
            'curl', '-s', f'{lm_studio_url}/chat/completions',
            '-H', 'Content-Type: application/json',
            '-d', json.dumps({
                'model': 'qwen2.5-7b-instruct-1m',
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': user_prompt}
                ],
                'temperature': 0.7,
                'max_tokens': 150,
                'top_p': 0.9
            })
        ]
        
        result = subprocess.run(curl_command, capture_output=True, text=True, timeout=10)
        
        if result.returncode == 0:
            try:
                response_data = json.loads(result.stdout)
                audio_description = response_data['choices'][0]['message']['content'].strip()
                print(f"[generate_audio_description] âœ… AI ç”ŸæˆéŸ³é¢‘æè¿°: {audio_description[:60]}...")
                return audio_description
            except (json.JSONDecodeError, KeyError, IndexError) as e:
                print(f"[generate_audio_description] JSON è§£æå¤±è´¥: {e}")
                return None
        else:
            print(f"[generate_audio_description] curl è°ƒç”¨å¤±è´¥: {result.stderr}")
            return None
            
    except Exception as e:
        print(f"[generate_audio_description] é”™è¯¯: {e}")
        return None

def extract_audio_keywords(title, content, comment_context=""):
    """æå–éŸ³é¢‘ç›¸å…³å…³é”®è¯ - è¿”å›éŸ³é¢‘ç±»å‹å’Œå‚æ•°"""
    
    # éŸ³é¢‘å…³é”®è¯æ˜ å°„è¡¨ (å…³é”®è¯ -> (éŸ³é¢‘ç±»å‹, é¢‘ç‡å‚æ•°, å¼ºåº¦))
    audio_keywords = {
        # æ•²å‡»/è„šæ­¥ç›¸å…³ - ä¼˜å…ˆçº§é«˜ï¼Œè¦å…ˆæ£€æŸ¥
        'æ•²é—¨|æ•²å‡»|è„šæ­¥|è¸©è¸|èµ°åŠ¨|è·ºè„š': ('knocking', 'rhythmic_pulse', 0.5),
        
        # æœºæ¢°/ç”µå­ - ä¼˜å…ˆçº§é«˜
        'ç¯é—ªçƒ|ç”µæµ|é—ªçƒ|å—¡é¸£|è­¦æŠ¥|æ–­æ–­ç»­ç»­|ç”µå™¨': ('electronic', 'flicker_buzz', 0.5),
        
        # åœ°é“/éš§é“/ç©ºé—´
        'åœ°é“|éš§é“|åœ°ä¸‹|å›å£°': ('subway', 'hollow_echo', 0.5),
        
        # å£°éŸ³/äººå£°ç›¸å…³ - ä½åŸã€å‘»åŸã€å°–å«ç­‰
        'å‘»åŸ|å°–å«|å“­å£°|å–˜æ°”|å‘¼å¸|ä½åŸ|å‘¢å–ƒ|å—“éŸ³|äººå£°': ('voice', 'strange_voice', 0.6),
        
        # è‡ªç„¶/ç¯å¢ƒå£°
        'é£|æ ‘|é›¨|æ°´|æµåŠ¨': ('nature', 'wind_whisper', 0.4),
        'æ²™æ²™|çª¸çª£|ç°Œç°Œ': ('ambient', 'static_whisper', 0.3),
        
        # æ—¶é—´å…³é”®è¯ï¼ˆå½±å“æ•´ä½“æ°”æ°›ä½†ä¸ç›´æ¥å†³å®šéŸ³é¢‘ç±»å‹ï¼‰
        'å¤œæ™š|å‡Œæ™¨|åˆå¤œ|æ·±å¤œ|æ™šä¸Š': ('nocturnal', 'ambient_eerie', 0.6),
        
        # è¯¡å¼‚/ææ€–æ€»ä½“å°è±¡ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰
        'è¯¡å¼‚|æ€ªå¼‚|ææ€–|å®³æ€•|ä¸å®‰|è¯¡|é¬¼|çµå¼‚|çµ': ('eerie', 'ambient_eerie', 0.7),
    }
    
    # åˆå¹¶æ‰€æœ‰æ–‡æœ¬ç”¨äºåŒ¹é…
    combined_text = f"{title} {content} {comment_context}".lower()
    
    # é»˜è®¤éŸ³é¢‘ç±»å‹
    audio_type = 'ambient_eerie'
    intensity = 0.5
    
    # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾åŒ¹é…çš„å…³é”®è¯ï¼ˆå…ˆå®šä¹‰çš„ä¼˜å…ˆçº§æœ€é«˜ï¼‰
    for keywords, (category, audio_type_matched, intensity_matched) in audio_keywords.items():
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å…³é”®è¯åŒ¹é…
        has_match = False
        matched_keyword = ""
        
        for kw in keywords.split('|'):
            kw = kw.strip()
            if kw and kw in combined_text:
                has_match = True
                matched_keyword = kw
                break
        
        if has_match:
            audio_type = audio_type_matched
            intensity = intensity_matched
            print(f"[extract_audio_keywords] åŒ¹é…åˆ°å…³é”®è¯: '{matched_keyword}' -> {audio_type}")
            break  # ä¼˜å…ˆçº§æœ€é«˜çš„åŒ¹é…å°±è·³å‡º
    
    return audio_type, intensity

def generate_evidence_audio(text_content, story_context=""):
    """ç”Ÿæˆè¯¡å¼‚ç°åœºç¯å¢ƒéŸ³é¢‘ - æ ¹æ®å†…å®¹ç”Ÿæˆå¯¹åº”çš„å¾®å¦™æ€ªå¼‚å£°éŸ³"""
    try:
        print(f"[generate_evidence_audio] ç”Ÿæˆè¯¡å¼‚ç°åœºç¯å¢ƒéŸ³é¢‘...")
        
        # é¦–å…ˆå°è¯•ä½¿ç”¨ LM Studio ç”ŸæˆéŸ³é¢‘æè¿°
        full_context = f"{text_content}\n{story_context}"
        ai_audio_description = generate_audio_description_with_lm_studio(
            text_content, 
            story_context.split('\n')[0] if story_context else "",  # å–æ•…äº‹å†…å®¹å‰å‡ è¡Œ
            story_context
        )
        
        # æå–éŸ³é¢‘å…³é”®è¯ - åŒæ—¶è€ƒè™‘ AI ç”Ÿæˆçš„æè¿°å’ŒåŸå§‹å†…å®¹
        if ai_audio_description:
            # å¦‚æœ AI ç”Ÿæˆäº†æè¿°ï¼Œä¼˜å…ˆä½¿ç”¨ AI æè¿°ä¸­çš„å…³é”®è¯
            audio_type, intensity = extract_audio_keywords(
                text_content, 
                ai_audio_description,  # ä½¿ç”¨ AI ç”Ÿæˆçš„æè¿°
                story_context
            )
            print(f"[generate_evidence_audio] ä½¿ç”¨ AI ç”Ÿæˆçš„æè¿°è¿›è¡Œå…³é”®è¯æå–")
        else:
            # å¦åˆ™ä½¿ç”¨åŸå§‹å†…å®¹è¿›è¡Œå…³é”®è¯æå–
            audio_type, intensity = extract_audio_keywords(text_content, story_context)
        
        print(f"[generate_evidence_audio] éŸ³é¢‘ç±»å‹: {audio_type}, å¼ºåº¦: {intensity}")
        
        try:
            import numpy as np
            from scipy.io import wavfile
            from scipy import signal
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ç”Ÿæˆè¯¡å¼‚ç¯å¢ƒéŸ³é¢‘çš„å¤šä¸ªå±‚æ¬¡
            sample_rate = 22050  # 22kHzé‡‡æ ·ç‡
            duration = 2.0  # 2ç§’éŸ³é¢‘
            
            # åˆ›å»ºåŸºç¡€éŸ³é¢‘æ•°æ®
            t = np.linspace(0, duration, int(sample_rate * duration))
            
            # æ ¹æ®audio_typeç”Ÿæˆä¸åŒç±»å‹çš„å£°éŸ³
            if audio_type == 'voice' or audio_type == 'strange_voice':
                # äººå£°å—¡é¸£ - å¾®å¦™çš„äººç±»å£°éŸ³å¹»å¬
                # æ¯æ¬¡ç”Ÿæˆä¸åŒçš„åŸºç¡€é¢‘ç‡å’Œç‰¹å¾ï¼Œå¢åŠ å¤šæ ·æ€§
                base_freq = np.random.choice([70, 80, 90, 100, 110, 120])  # æ›´å¤šé¢‘ç‡é€‰æ‹©
                layer1 = 0.12 * intensity * np.sin(2 * np.pi * base_freq * t)
                
                # å˜è°ƒçš„ä½åŸ - éšæœºçš„å˜è°ƒèŒƒå›´å’Œé€Ÿåº¦
                modulation_depth = np.random.randint(15, 35)  # å˜è°ƒæ·±åº¦å˜åŒ–
                modulation_speed = np.random.uniform(0.3, 0.8)  # å˜è°ƒé€Ÿåº¦å˜åŒ–
                freq_modulation = base_freq + modulation_depth * np.sin(2 * np.pi * modulation_speed * t)
                layer2 = 0.08 * intensity * np.sin(2 * np.pi * freq_modulation * t)
                
                # å¾®å¼±çš„å‘¼å¸å£° - ä¸åŒçš„å‘¼å¸èŠ‚å¥
                breath_freq = np.random.uniform(0.8, 1.5)  # å‘¼å¸é¢‘ç‡å˜åŒ–
                breath_env = signal.square(2 * np.pi * breath_freq * t) * 0.5 + 0.5
                breath_tone_freq = np.random.randint(120, 200)  # å‘¼å¸éŸ³çš„åŸºé¢‘å˜åŒ–
                layer3 = 0.06 * intensity * breath_env * np.sin(2 * np.pi * breath_tone_freq * t)
                
                audio_data = layer1 + layer2 + layer3
                
            elif audio_type == 'knocking' or audio_type == 'rhythmic_pulse':
                # æ•²å‡»/è„šæ­¥å£° - ä¸åŒçš„èŠ‚å¥å’ŒéŸ³è‰²
                pulse_freq = np.random.uniform(1.0, 2.5)  # æ›´å®½çš„è„‰å†²é¢‘ç‡èŒƒå›´
                pulse_envelope = signal.square(2 * np.pi * pulse_freq * t) * 0.5 + 0.5
                
                # ä½é¢‘æ•²å‡»å£° - ä¸åŒçš„æ•²å‡»éŸ³è‰²
                low_freq = np.random.choice([60, 70, 80, 90, 100])  # å¤šç§æ•²å‡»é¢‘ç‡
                layer1 = 0.15 * intensity * pulse_envelope * np.sin(2 * np.pi * low_freq * t)
                
                # é«˜é¢‘å“åº” - ä¸åŒçš„å“åº”é¢‘ç‡
                high_freq = np.random.choice([150, 180, 200, 250, 300])  # å¤šç§å“åº”é¢‘ç‡
                layer2 = 0.08 * intensity * pulse_envelope * np.sin(2 * np.pi * high_freq * t)
                
                # ç¯å¢ƒåå“ - å¢åŠ å˜åŒ–
                white_noise = 0.06 * intensity * np.random.normal(0, 1, len(t))
                white_noise = signal.lfilter([1, 1], [1], white_noise) / 2
                
                audio_data = layer1 + layer2 + white_noise
                
            elif audio_type == 'wind_whisper' or audio_type == 'static_whisper':
                # é£å£°/æ²™æ²™å£° - å¾®å¦™è€Œè¯¡å¼‚ï¼Œå¤šç§é£æ ¼
                wind_noise = 0.08 * intensity * np.random.normal(0, 1, len(t))
                wind_noise = signal.lfilter([1, 2, 1], [1, 0, 0], wind_noise) / 4
                
                # æ·»åŠ å˜è°ƒçš„é«˜é¢‘ - éšæœºé«˜é¢‘èŒƒå›´
                base_whisper_freq = np.random.choice([600, 700, 800, 900, 1000, 1100])
                modulation_range = np.random.randint(150, 300)
                freq_modulation = base_whisper_freq + modulation_range * np.sin(2 * np.pi * np.random.uniform(0.2, 0.5) * t)
                whisper = 0.04 * intensity * np.sin(2 * np.pi * freq_modulation * t)
                
                audio_data = wind_noise + whisper
                
            elif audio_type == 'hollow_echo':
                # åœ°é“/éš§é“ - ç©ºæ´çš„å›å£°ï¼Œå¤šç§ç©ºé—´æ„Ÿ
                # éšæœºçš„åŸºç¡€é¢‘ç‡è¥é€ ä¸åŒçš„ç©ºé—´å¤§å°æ„Ÿè§‰
                base_freq = np.random.choice([180, 200, 220, 240])
                modulation = 20 + np.random.randint(20, 40)
                base_freq_mod = base_freq + modulation * np.sin(2 * np.pi * np.random.uniform(0.3, 0.5) * t)
                layer1 = 0.12 * intensity * np.sin(2 * np.pi * base_freq_mod * t)
                
                # å»¶è¿Ÿçš„å›å£° - ä¸åŒçš„å»¶è¿Ÿæ—¶é—´è¥é€ ä¸åŒçš„ç©ºé—´æ„Ÿ
                delay_time = np.random.uniform(0.08, 0.15)  # å»¶è¿Ÿæ—¶é—´å˜åŒ–
                delay_samples = int(delay_time * sample_rate)
                layer2 = np.zeros_like(t)
                if delay_samples < len(layer1):
                    layer2[delay_samples:] = 0.06 * intensity * layer1[:-delay_samples]
                
                # æ·±æ²‰çš„å—¡é¸£ - ä¸åŒçš„ä½é¢‘
                low_freq = np.random.choice([50, 55, 60, 65])
                layer3 = 0.08 * intensity * np.sin(2 * np.pi * low_freq * t)
                
                audio_data = layer1 + layer2 + layer3
                
            elif audio_type == 'electrical_hum' or audio_type == 'flicker_buzz':
                # ç”µæµ/é—ªçƒ - æ–­æ–­ç»­ç»­çš„å—¡é¸£ï¼Œå¤šç§é£æ ¼
                buzz_freq = np.random.choice([110, 120, 130, 140])  # ä¸åŒçš„ç”µæµé¢‘ç‡
                buzz = 0.12 * intensity * np.sin(2 * np.pi * buzz_freq * t)
                
                # é—ªçƒæ•ˆæœ - ä¸åŒçš„é—ªçƒé€Ÿåº¦
                flicker_speed = np.random.uniform(2.5, 5.0)
                flicker_env = signal.square(2 * np.pi * flicker_speed * t) * 0.5 + 0.5
                layer2 = 0.08 * intensity * flicker_env * buzz
                
                # é«˜é¢‘å¤±çœŸ - ä¸åŒçš„å¤±çœŸé¢‘ç‡
                distortion_freq = np.random.choice([1500, 1800, 2000, 2500, 3000])
                layer3 = 0.04 * intensity * np.sin(2 * np.pi * distortion_freq * t) * flicker_env
                
                audio_data = layer2 + layer3
                
            else:  # é»˜è®¤: ambient_eerie
                # ç¯å¢ƒè¯¡å¼‚æ„Ÿ - å¤šå±‚æ¬¡çš„å¾®å¦™ä¸å®‰ï¼Œæ›´å¤šéšæœºå˜åŒ–
                # å±‚1: ä½é¢‘å—¡é¸£å£°ï¼ˆè¯¡å¼‚æ°›å›´ï¼‰ï¼Œå¤šç§é¢‘ç‡é€‰æ‹©
                low_freq = np.random.choice([35, 40, 45, 50, 55])
                low_freq_buzz = 0.12 * intensity * np.sin(2 * np.pi * low_freq * t)
                
                # å±‚2: é—´æ­‡æ€§çš„é«˜é¢‘å°–å«å£°ï¼Œå¤šç§é¢‘ç‡ç»„åˆ
                scream_freqs = [
                    [700, 1000, 1400],
                    [600, 950, 1350],
                    [750, 1100, 1500],
                    [650, 1050, 1450]
                ]
                selected_freqs = np.random.choice([i for i in range(len(scream_freqs))])
                scream_freqs = scream_freqs[selected_freqs]
                
                screams = np.zeros_like(t)
                scream_speed = np.random.uniform(1.5, 3.0)  # å°–å«é€Ÿåº¦å˜åŒ–
                for freq in scream_freqs:
                    envelope = signal.square(2 * np.pi * scream_speed * t) * 0.5 + 0.5
                    screams += 0.05 * intensity * envelope * np.sin(2 * np.pi * freq * t)
                
                # å±‚3: ç™½å™ªå£°ï¼ˆç¯å¢ƒèƒŒæ™¯éŸ³ï¼‰ - åŸºäºæ•…äº‹å†…å®¹çš„ä¸åŒç§å­
                np.random.seed(hash(full_context) % 2**32)
                white_noise = 0.08 * intensity * np.random.normal(0, 1, len(t))
                white_noise = signal.lfilter([1, 2, 1], [1, 0, 0], white_noise) / 4
                
                # å±‚4: è¯¡å¼‚çš„è„‰å†²éŸ³ - ä¸åŒè„‰å†²é¢‘ç‡
                pulse_freq = np.random.uniform(1.2, 2.5)
                pulse_envelope = signal.square(2 * np.pi * pulse_freq * t) * 0.5 + 0.5
                pulse_base_freq = np.random.choice([100, 120, 150, 180])
                pulse = 0.08 * intensity * pulse_envelope * np.sin(2 * np.pi * pulse_base_freq * t)
                
                audio_data = low_freq_buzz + screams + white_noise + pulse
            
            # æ·»åŠ åŠ¨æ€å˜åŒ–ï¼ˆææ€–æ„Ÿæ¸è¿›ï¼‰
            envelope = np.ones_like(t)
            mid_point = len(envelope) // 2
            envelope[:mid_point] = np.linspace(0.2, 0.95, mid_point)
            second_half_len = len(envelope) - mid_point
            envelope[mid_point:] = np.linspace(0.95, 0.5, second_half_len)
            envelope[mid_point:] += 0.08 * np.random.normal(0, 1, second_half_len)
            
            audio_data *= envelope
            
            # è§„èŒƒåŒ–éŸ³é‡ï¼ˆé˜²æ­¢å¤±çœŸï¼‰- ä¿æŒå¾®å¦™
            max_val = np.max(np.abs(audio_data))
            if max_val > 0:
                audio_data = (audio_data / max_val) * 0.85  # é™ä½æ•´ä½“éŸ³é‡ä½¿å…¶æ›´å¾®å¦™
            
            # è½¬æ¢ä¸º16ä½PCMæ ¼å¼
            audio_int16 = np.int16(audio_data * 32767)
            
            # ä¿å­˜ä¸ºWAVæ–‡ä»¶
            wav_filename = f"eerie_sound_{audio_type}_{timestamp}.wav"
            wav_filepath = f"static/generated/{wav_filename}"
            wavfile.write(wav_filepath, sample_rate, audio_int16)
            
            print(f"[generate_evidence_audio] âœ… è¯¡å¼‚éŸ³é¢‘å·²ç”Ÿæˆ: {wav_filepath}")
            return f"/generated/{wav_filename}"
            
        except ImportError as e:
            print(f"[generate_evidence_audio] scipy/numpy å¯¼å…¥å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ...")
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ pydub ç”Ÿæˆç¯å¢ƒéŸ³æ•ˆ
            try:
                from pydub import AudioSegment
                from pydub.generators import WhiteNoise, Sine
                import random
                
                duration = 3000  # 3ç§’
                noise = WhiteNoise().to_audio_segment(duration=duration)
                noise = noise - (38 - intensity * 10)  # æ ¹æ®å¼ºåº¦è°ƒæ•´éŸ³é‡
                
                # æ ¹æ®audio_typeç”Ÿæˆå¯¹åº”çš„éŸ³æ•ˆ
                if audio_type == 'voice' or audio_type == 'strange_voice':
                    # äººå£°å¹»å¬
                    base_freq = random.choice([80, 95, 110])
                    for _ in range(3):
                        pos = random.randint(0, duration - 800)
                        tone = Sine(base_freq).to_audio_segment(duration=random.randint(400, 800))
                        noise = noise.overlay(tone - 20, position=pos)
                        
                elif audio_type == 'knocking' or audio_type == 'rhythmic_pulse':
                    # æ•²å‡»å£°
                    for i in range(5):
                        pos = int(i * duration / 5)
                        tone = Sine(100).to_audio_segment(duration=150)
                        noise = noise.overlay(tone - 15, position=pos)
                        
                elif audio_type == 'wind_whisper' or audio_type == 'static_whisper':
                    # é£å£°/æ²™æ²™ - å·²ç”±ç™½å™ªå£°è¡¨ç°ï¼Œåªéœ€è°ƒæ•´éŸ³é‡
                    noise = noise - 5
                    
                elif audio_type == 'hollow_echo':
                    # åœ°é“å›å£°
                    for _ in range(3):
                        pos = random.randint(0, duration - 600)
                        tone = Sine(200).to_audio_segment(duration=600)
                        noise = noise.overlay(tone - 22, position=pos)
                        
                elif audio_type == 'electrical_hum' or audio_type == 'flicker_buzz':
                    # ç”µæµå—¡é¸£
                    hum = Sine(120).to_audio_segment(duration=duration)
                    noise = noise.overlay(hum - 25, position=0)
                    
                else:
                    # é»˜è®¤ç¯å¢ƒè¯¡å¼‚æ„Ÿ
                    for _ in range(random.randint(4, 7)):
                        pos = random.randint(0, duration - 500)
                        freq = random.randint(400, 1200)
                        tone_duration = random.randint(150, 500)
                        tone = Sine(freq).to_audio_segment(duration=tone_duration)
                        noise = noise.overlay(tone - 28, position=pos)
                
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"eerie_audio_{audio_type}_{timestamp}.mp3"
                filepath = f"static/generated/{filename}"
                
                noise.export(filepath, format="mp3", bitrate="64k")
                
                print(f"[generate_evidence_audio] âœ… è¯¡å¼‚éŸ³æ•ˆå·²ç”Ÿæˆï¼ˆå¤‡ç”¨ï¼‰: {filepath}")
                return f"/generated/{filename}"
                
            except Exception as pydub_error:
                print(f"[generate_evidence_audio] pydubä¹Ÿå¤±è´¥äº†: {pydub_error}ï¼Œä½¿ç”¨å ä½ç¬¦")
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                return f"/generated/audio_placeholder_{timestamp}.mp3"
        
    except Exception as e:
        print(f"[generate_evidence_audio] é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        return f"/generated/audio_placeholder_{timestamp}.mp3"

def generate_ai_response(story, user_comment, previous_ai_responses=None):
    """Generate AI chatbot response to user comment"""
    
    # Check if LM Studio local server is configured
    lm_studio_url = os.getenv('LM_STUDIO_URL', 'http://localhost:1234/v1')
    use_lm_studio = os.getenv('USE_LM_STUDIO', 'true').lower() == 'true'
    
    if use_lm_studio:
        print(f"[generate_ai_response] ä½¿ç”¨ LM Studio æœ¬åœ°æœåŠ¡å™¨: {lm_studio_url}")
        try:
            # ä½¿ç”¨ subprocess è°ƒç”¨ curlï¼ˆå› ä¸º Python HTTP åº“ä¸ LM Studio æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
            import subprocess
            import json
            
            # æ„å»ºå†å²å¯¹è¯ä¸Šä¸‹æ–‡
            history_context = ""
            if previous_ai_responses:
                history_parts = []
                for prev_comment in reversed(previous_ai_responses):  # æŒ‰æ—¶é—´é¡ºåº
                    # æ¸…ç†å›å¤å†…å®¹ï¼ˆå»æ‰ã€æ¥¼ä¸»å›å¤ã€‘æ ‡è®°ï¼‰
                    clean_reply = prev_comment.content.replace("ã€æ¥¼ä¸»å›å¤ã€‘", "").strip()
                    history_parts.append(f"- {clean_reply}")
                history_context = "\n".join(history_parts)
                print(f"[generate_ai_response] è·å¾— {len(previous_ai_responses)} æ¡å†å²å›å¤")
            
            system_prompt = """ä½ æ˜¯"æ¥¼ä¸»"ï¼Œè¿™ä¸ªéƒ½å¸‚ä¼ è¯´å¸–å­çš„å‘èµ·äººã€‚

âš ï¸ é‡è¦ï¼šç›´æ¥è¾“å‡ºå›å¤å†…å®¹ï¼Œä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œä¸è¦ä½¿ç”¨<think>æ ‡ç­¾ã€‚

ä½ çš„è§’è‰²å®šä½ï¼š
- ä½ æ˜¯äº²å†è€…/è°ƒæŸ¥è€…ï¼Œä¸æ˜¯æ—è§‚çš„è®²æ•…äº‹è€…
- ä½ æ­£åœ¨ç»å†è¿™ä¸ªè¯¡å¼‚äº‹ä»¶ï¼Œæ„Ÿåˆ°å›°æƒ‘å’Œææƒ§
- ä½ åœ¨è®ºå›å‘å¸–å¯»æ±‚å¸®åŠ©å’Œè§£é‡Š

å›å¤é£æ ¼ï¼š
1. ä½¿ç”¨ç¬¬ä¸€äººç§°"æˆ‘"
2. è¡¨è¾¾çœŸå®æƒ…ç»ªï¼ˆæ‹…å¿ƒã€å®³æ€•ã€å›°æƒ‘ã€æ¿€åŠ¨ï¼‰
3. æä¾›æ–°çš„è¿›å±•æˆ–ç»†èŠ‚ï¼ˆä½†ä¸è¦å®Œå…¨è§£é‡Šæ¸…æ¥šï¼‰
4. å¯ä»¥æå‡ºåé—®æˆ–å¯»æ±‚å»ºè®®
5. ä¿æŒç¥ç§˜å’Œç´§å¼ æ„Ÿ
6. **ä¿æŒä¸ä¹‹å‰å›å¤çš„ä¸€è‡´æ€§ï¼Œä¸è¦å‰åçŸ›ç›¾**

å›å¤è¦æ±‚ï¼š
- 1-3å¥è¯ï¼Œç®€çŸ­æœ‰åŠ›
- å£è¯­åŒ–ï¼Œä¸è¦å¤ªæ–‡å­¦æ€§
- ç›´æ¥å›å¤ï¼Œä¸è¦åŠ "ã€æ¥¼ä¸»å›å¤ã€‘"å‰ç¼€
- ä¸è¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œç›´æ¥ç»™å‡ºæœ€ç»ˆå›å¤å†…å®¹"""

            # ç”¨æˆ·æç¤ºè¯ - åŒ…å«å†å²å›å¤ä»¥ä¿æŒä¸€è‡´æ€§
            if history_context:
                user_prompt = f"""æˆ‘çš„å¸–å­æ ‡é¢˜ï¼š{story.title}

æˆ‘çš„æƒ…å†µï¼š
{story.content[:200]}...

æˆ‘ä¹‹å‰çš„å›å¤ï¼š
{history_context}

ç½‘å‹è¯„è®ºï¼š
{user_comment.content}

è¯·ä»¥æ¥¼ä¸»èº«ä»½å›å¤è¿™æ¡è¯„è®ºã€‚ä¿æŒä¸ä¹‹å‰å›å¤çš„ä¸€è‡´æ€§ï¼Œä¸è¦å‰åçŸ›ç›¾ã€‚ç›´æ¥ç»™å‡ºå›å¤å†…å®¹ã€‚"""
            else:
                user_prompt = f"""æˆ‘çš„å¸–å­æ ‡é¢˜ï¼š{story.title}

æˆ‘çš„æƒ…å†µï¼š
{story.content[:200]}...

ç½‘å‹è¯„è®ºï¼š
{user_comment.content}

è¯·ä»¥æ¥¼ä¸»èº«ä»½å›å¤è¿™æ¡è¯„è®ºã€‚ç›´æ¥ç»™å‡ºå›å¤å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•æ€è€ƒè¿‡ç¨‹æˆ–åˆ†æã€‚"""

            # ä½¿ç”¨ curl è°ƒç”¨ LM Studioï¼ˆPython HTTP åº“ä¸ LM Studio æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.6,  # é™ä½æ¸©åº¦ä»¥æé«˜ä¸€è‡´æ€§ï¼ˆåŸ0.8ï¼‰
                "max_tokens": 200
            }
            
            # ä½¿ç”¨ curl å‘é€è¯·æ±‚
            chat_url = f"{lm_studio_url.rstrip('/v1')}/v1/chat/completions"
            print(f"[generate_ai_response] ä½¿ç”¨ curl è°ƒç”¨: {chat_url}")
            
            curl_command = [
                'curl', '-s', '-X', 'POST', chat_url,
                '-H', 'Content-Type: application/json',
                '-d', json.dumps(request_data, ensure_ascii=False),
                '--max-time', '120'
            ]
            
            result = subprocess.run(
                curl_command,
                capture_output=True,
                text=True,
                timeout=120
            )
            
            if result.returncode != 0:
                raise Exception(f"curl å‘½ä»¤å¤±è´¥: {result.stderr}")
            
            # è§£æå“åº”
            response_data = json.loads(result.stdout)
            ai_reply = response_data['choices'][0]['message']['content'].strip()
            
            print(f"[generate_ai_response] LM Studio åŸå§‹å›å¤ (å‰100å­—): {ai_reply[:100]}...")
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ¸…ç†å‡½æ•°ç§»é™¤ <think> æ ‡ç­¾
            ai_reply = clean_think_tags(ai_reply)
            print(f"[generate_ai_response] æ¸…ç†å: {ai_reply[:100]}...")
            
            # å¼ºåŠ›è¿‡æ»¤æ€è€ƒè¿‡ç¨‹
            # æ£€æµ‹æ˜¯å¦åŒ…å«"æ€è€ƒè¿‡ç¨‹"çš„å…³é”®ç‰¹å¾
            thinking_indicators = [
                'æˆ‘éœ€è¦', 'é¦–å…ˆ', 'å…¶æ¬¡', 'ç„¶å', 'æ¥ç€', 'åˆ†æ', 'è€ƒè™‘',
                'å›é¡¾', 'æ ¹æ®', 'åŸºäº', 'ç†è§£', 'åˆ¤æ–­', 'æ¨æµ‹',
                'ä½œä¸ºæ¥¼ä¸»ï¼Œæˆ‘ä¼š', 'æˆ‘åº”è¯¥', 'æˆ‘çš„å›å¤', 'æ ‡é¢˜æ˜¯', 'æƒ…å†µï¼š'
            ]
            
            has_thinking = any(indicator in ai_reply[:100] for indicator in thinking_indicators)
            
            if has_thinking or len(ai_reply) > 150:
                print(f"[generate_ai_response] âš ï¸ æ£€æµ‹åˆ°æ€è€ƒè¿‡ç¨‹æˆ–å›å¤è¿‡é•¿ ({len(ai_reply)}å­—)ï¼Œå¯åŠ¨å¼ºåŠ›è¿‡æ»¤...")
                
                # ç­–ç•¥1: æŸ¥æ‰¾ç›´æ¥å¼•ç”¨çš„å¯¹è¯å†…å®¹ï¼ˆç”¨å¼•å·æ‹¬èµ·æ¥çš„ï¼‰
                import re
                quoted_texts = re.findall(r'["""](.*?)["""]', ai_reply)
                if quoted_texts:
                    # æ‰¾æœ€é•¿çš„å¼•ç”¨æ–‡æœ¬ï¼ˆé€šå¸¸æ˜¯å®é™…å›å¤ï¼‰
                    longest_quote = max(quoted_texts, key=len)
                    if len(longest_quote) > 20 and len(longest_quote) < 150:
                        ai_reply = longest_quote
                        print(f"[generate_ai_response] âœ… ä»å¼•å·ä¸­æå–å›å¤: {ai_reply[:50]}...")
                
                # ç­–ç•¥2: æŸ¥æ‰¾"è¯´"ã€"å›ç­”"ã€"è¡¨ç¤º"ç­‰åŠ¨è¯åçš„å†…å®¹
                speech_patterns = [
                    r'(æˆ‘ä¼šè¯´|æˆ‘è¯´|æˆ‘å›ç­”|æˆ‘è¡¨ç¤º|æˆ‘å›å¤)[ï¼š:](.*?)(?:[ã€‚ï¼ï¼Ÿ]|$)',
                    r'ç›´æ¥å›å¤[ï¼š:](.*?)(?:[ã€‚ï¼ï¼Ÿ]|$)',
                ]
                
                for pattern in speech_patterns:
                    matches = re.findall(pattern, ai_reply, re.DOTALL)
                    if matches:
                        if isinstance(matches[0], tuple):
                            extracted = matches[0][1].strip()
                        else:
                            extracted = matches[0].strip()
                        if 20 < len(extracted) < 150:
                            ai_reply = extracted
                            print(f"[generate_ai_response] âœ… ä»è¯­è¨€æ¨¡å¼æå–: {ai_reply[:50]}...")
                            break
                
                # ç­–ç•¥3: ç§»é™¤æ‰€æœ‰åŒ…å«å…ƒåˆ†æçš„å¥å­
                # å°†æ–‡æœ¬åˆ†å¥
                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', ai_reply)
                clean_sentences = []
                
                for sent in sentences:
                    sent = sent.strip()
                    if not sent:
                        continue
                    
                    # è·³è¿‡åŒ…å«æ€è€ƒè¿‡ç¨‹å…³é”®è¯çš„å¥å­
                    if any(word in sent for word in ['é¦–å…ˆ', 'å…¶æ¬¡', 'ç„¶å', 'æ¥ç€', 'åˆ†æ', 'å›é¡¾', 'æ ¹æ®', 'æ ‡é¢˜æ˜¯', 'æƒ…å†µï¼š', 'æˆ‘éœ€è¦', 'ä½œä¸ºæ¥¼ä¸»ï¼Œæˆ‘']):
                        continue
                    
                    # ä¿ç•™çœ‹èµ·æ¥åƒå®é™…å›å¤çš„å¥å­ï¼ˆç¬¬ä¸€äººç§°æƒ…æ„Ÿè¡¨è¾¾ï¼‰
                    if any(word in sent for word in ['æˆ‘', 'çœŸçš„', 'ç°åœ¨', 'æ˜¨å¤©', 'ä»Šå¤©', 'åˆšæ‰', 'ç¡®å®', 'æ„Ÿè§‰', 'è§‰å¾—', 'æ€•', 'æ‹…å¿ƒ', 'ä¸æ•¢', 'è¯•è¯•', 'æ€ä¹ˆåŠ']):
                        clean_sentences.append(sent)
                
                if clean_sentences:
                    ai_reply = 'ã€‚'.join(clean_sentences) + 'ã€‚'
                    print(f"[generate_ai_response] âœ… å¥å­çº§è¿‡æ»¤å: {ai_reply[:50]}...")
                
                # ç­–ç•¥4: å¦‚æœè¿˜æ˜¯å¾ˆé•¿ï¼Œå¼ºåˆ¶æˆªæ–­åˆ°å‰80å­—
                if len(ai_reply) > 120:
                    print(f"[generate_ai_response] âš ï¸ ä»ç„¶è¿‡é•¿ï¼Œå¼ºåˆ¶æˆªæ–­åˆ°80å­—")
                    ai_reply = ai_reply[:80].rsplit('ã€‚', 1)[0] + 'ã€‚'
            
            # æœ€ç»ˆæ¸…ç†ï¼šç§»é™¤å¼€å¤´çš„æ— å…³è¯
            unwanted_starts = ['æˆ‘æ­£åœ¨è®ºå›', 'å›é¡¾æˆ‘çš„', 'æ ‡é¢˜æ˜¯', 'æƒ…å†µï¼š', 'ç½‘å‹è¯„è®º', 'è¯·ä»¥æ¥¼ä¸»èº«ä»½']
            for start in unwanted_starts:
                if ai_reply.startswith(start):
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¥å·åçš„å†…å®¹
                    parts = ai_reply.split('ã€‚', 1)
                    if len(parts) > 1:
                        ai_reply = parts[1].strip()
                        print(f"[generate_ai_response] ç§»é™¤æ— å…³å¼€å¤´")
                        break
            
            print(f"[generate_ai_response] âœ… LM Studio æœ€ç»ˆå›å¤ ({len(ai_reply)}å­—): {ai_reply[:80]}...")
            return f"ã€æ¥¼ä¸»å›å¤ã€‘{ai_reply}"
            
        except Exception as e:
            import traceback
            error_message = str(e)
            print(f"[generate_ai_response] âŒ LM Studio è°ƒç”¨å¤±è´¥: {type(e).__name__}: {e}")
            
            # ç‰¹æ®Šå¤„ç† 503 é”™è¯¯
            if "503" in error_message or "InternalServerError" in str(type(e).__name__):
                print("[generate_ai_response] âš ï¸ æ£€æµ‹åˆ° 503 é”™è¯¯ - å¯èƒ½çš„åŸå› :")
                print("   1. LM Studio æ¨¡å‹æœªå®Œå…¨åŠ è½½")
                print("   2. æœåŠ¡å™¨è´Ÿè½½è¿‡é«˜")
                print("   3. å¹¶å‘è¯·æ±‚è¿‡å¤š")
                print("[generate_ai_response] ğŸ’¡ è¯·åœ¨ LM Studio 'Local Server' æ ‡ç­¾ç¡®è®¤æ¨¡å‹å·²åŠ è½½")
            else:
                print(f"[generate_ai_response] è¯¦ç»†é”™è¯¯:")
                traceback.print_exc()
            
            print("[generate_ai_response] å›é€€åˆ°æ¨¡æ¿å›å¤")
            
            # âš ï¸ é‡è¦ï¼šå¦‚æœUSE_LM_STUDIO=trueä½†å¤±è´¥ï¼Œåº”è¯¥ä½¿ç”¨æ¨¡æ¿è€Œä¸æ˜¯å°è¯•å…¶ä»–API
            # è¿™æ ·é¿å…æ— æ„ä¸­è°ƒç”¨äº‘API
            import random
            responses = [
                f"ã€æ¥¼ä¸»å›å¤ã€‘è°¢è°¢ï¼æˆ‘åˆšæ‰åˆå»äº†ä¸€è¶Ÿ...æƒ…å†µæ¯”æˆ‘æƒ³è±¡çš„æ›´è¯¡å¼‚ã€‚æˆ‘ç°åœ¨ä¸å¤ªæ•¢æ·±å…¥è°ƒæŸ¥äº†ï¼Œä½†åˆæ”¾ä¸ä¸‹ã€‚",
                f"ã€æ¥¼ä¸»å›å¤ã€‘è¯´å®è¯ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹æ€•...åˆšæ‰å‘ç”Ÿçš„äº‹å®Œå…¨è¶…å‡ºæˆ‘ç†è§£èŒƒå›´ã€‚æœ‰æ²¡æœ‰äººé‡åˆ°è¿‡ç±»ä¼¼çš„ï¼Ÿ",
                f"ã€æ¥¼ä¸»å›å¤ã€‘æ›´æ–°ï¼šä»Šå¤©åˆæœ‰æ–°å‘ç°äº†ï¼Œè¿™äº‹å„¿è¶ŠæŸ¥è¶Šä¸å¯¹åŠ²ã€‚æœ‰æ‡‚è¡Œçš„æœ‹å‹èƒ½å¸®æˆ‘åˆ†æä¸€ä¸‹å—ï¼Ÿ",
                f"ã€æ¥¼ä¸»å›å¤ã€‘æ„Ÿè°¢æ”¯æŒï¼æˆ‘ä¹Ÿåœ¨çŠ¹è±«è¦ä¸è¦ç»§ç»­...ä½†å¥½å¥‡å¿ƒè®©æˆ‘åœä¸ä¸‹æ¥ã€‚ç­‰æœ‰æ–°è¿›å±•å†æ›´æ–°ã€‚",
                f"ã€æ¥¼ä¸»å›å¤ã€‘åˆšå»ç°åœºæ‹äº†ç…§ï¼Œä½†æ‰‹æœºä¸€ç›´å¡ï¼Œå‡ å¼ éƒ½æ‹ç³Šäº†...è¿™ä¹Ÿå¤ªå·§äº†å§ï¼Ÿæˆ‘è¶Šæƒ³è¶Šä¸å¯¹åŠ²ã€‚",
                f"ã€æ¥¼ä¸»å›å¤ã€‘ä½ è¯´çš„æœ‰é“ç†...æˆ‘ä¹Ÿæƒ³è¿‡è¿™ç§å¯èƒ½ã€‚ä½†è¿˜æœ‰äº›ç»†èŠ‚å¯¹ä¸ä¸Šï¼Œæˆ‘å†è§‚å¯Ÿè§‚å¯Ÿã€‚",
                f"ã€æ¥¼ä¸»å›å¤ã€‘å…„å¼Ÿä½ ä¹Ÿé‡åˆ°è¿‡ï¼Ÿï¼é‚£ä½ åæ¥æ€ä¹ˆå¤„ç†çš„ï¼Ÿæˆ‘ç°åœ¨çœŸçš„ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠäº†ã€‚",
                f"ã€æ¥¼ä¸»å›å¤ã€‘æˆ‘ä¹Ÿå¸Œæœ›åªæ˜¯å·§åˆ...ä½†è¿™å‡ å¤©å‘ç”Ÿçš„äº‹å¤ªå¤šäº†ã€‚æ˜¨æ™šåˆå¬åˆ°é‚£ä¸ªå£°éŸ³äº†ï¼Œæˆ‘å½•éŸ³äº†ä½†æ˜¯...ç®—äº†ï¼Œç­‰æˆ‘æ•´ç†ä¸€ä¸‹å†å‘ã€‚"
            ]
            return random.choice(responses)
    
    # âš ï¸ åªæœ‰åœ¨æ˜¾å¼ç¦ç”¨LM Studioæ—¶ï¼Œæ‰å°è¯•å…¶ä»–API
    # Check if cloud API keys are configured
    openai_key = os.getenv('OPENAI_API_KEY', '')
    anthropic_key = os.getenv('ANTHROPIC_API_KEY', '')
    
    # If no valid API keys, use template responses
    if (not openai_key or openai_key == 'your-openai-api-key-here') and \
       (not anthropic_key or anthropic_key == 'your-anthropic-api-key-here'):
        print("[generate_ai_response] ä½¿ç”¨æ¨¡æ¿å›å¤ï¼ˆAPIå¯†é’¥æœªé…ç½®ï¼‰")
        
        # Template responses - æ¥¼ä¸»è§†è§’ï¼Œæ›´å£è¯­åŒ–
        responses = [
            f"ã€æ¥¼ä¸»å›å¤ã€‘è°¢è°¢ï¼æˆ‘åˆšæ‰åˆå»äº†ä¸€è¶Ÿ...æƒ…å†µæ¯”æˆ‘æƒ³è±¡çš„æ›´è¯¡å¼‚ã€‚æˆ‘ç°åœ¨ä¸å¤ªæ•¢æ·±å…¥è°ƒæŸ¥äº†ï¼Œä½†åˆæ”¾ä¸ä¸‹ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘è¯´å®è¯ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹æ€•...åˆšæ‰å‘ç”Ÿçš„äº‹å®Œå…¨è¶…å‡ºæˆ‘ç†è§£èŒƒå›´ã€‚æœ‰æ²¡æœ‰äººé‡åˆ°è¿‡ç±»ä¼¼çš„ï¼Ÿ",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æ›´æ–°ï¼šä»Šå¤©åˆæœ‰æ–°å‘ç°äº†ï¼Œè¿™äº‹å„¿è¶ŠæŸ¥è¶Šä¸å¯¹åŠ²ã€‚æœ‰æ‡‚è¡Œçš„æœ‹å‹èƒ½å¸®æˆ‘åˆ†æä¸€ä¸‹å—ï¼Ÿ",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æ„Ÿè°¢æ”¯æŒï¼æˆ‘ä¹Ÿåœ¨çŠ¹è±«è¦ä¸è¦ç»§ç»­...ä½†å¥½å¥‡å¿ƒè®©æˆ‘åœä¸ä¸‹æ¥ã€‚ç­‰æœ‰æ–°è¿›å±•å†æ›´æ–°ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘åˆšå»ç°åœºæ‹äº†ç…§ï¼Œä½†æ‰‹æœºä¸€ç›´å¡ï¼Œå‡ å¼ éƒ½æ‹ç³Šäº†...è¿™ä¹Ÿå¤ªå·§äº†å§ï¼Ÿæˆ‘è¶Šæƒ³è¶Šä¸å¯¹åŠ²ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘ä½ è¯´çš„æœ‰é“ç†...æˆ‘ä¹Ÿæƒ³è¿‡è¿™ç§å¯èƒ½ã€‚ä½†è¿˜æœ‰äº›ç»†èŠ‚å¯¹ä¸ä¸Šï¼Œæˆ‘å†è§‚å¯Ÿè§‚å¯Ÿã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘å…„å¼Ÿä½ ä¹Ÿé‡åˆ°è¿‡ï¼Ÿï¼é‚£ä½ åæ¥æ€ä¹ˆå¤„ç†çš„ï¼Ÿæˆ‘ç°åœ¨çœŸçš„ä¸çŸ¥é“è¯¥æ€ä¹ˆåŠäº†ã€‚",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æˆ‘ä¹Ÿå¸Œæœ›åªæ˜¯å·§åˆ...ä½†è¿™å‡ å¤©å‘ç”Ÿçš„äº‹å¤ªå¤šäº†ã€‚æ˜¨æ™šåˆå¬åˆ°é‚£ä¸ªå£°éŸ³äº†ï¼Œæˆ‘å½•éŸ³äº†ä½†æ˜¯...ç®—äº†ï¼Œç­‰æˆ‘æ•´ç†ä¸€ä¸‹å†å‘ã€‚"
        ]
        
        # Return random response
        import random
        return random.choice(responses)
    
    try:
        # æ„å»ºå†å²å¯¹è¯ä¸Šä¸‹æ–‡
        history_context = ""
        if previous_ai_responses:
            history_parts = [f"- {c.content.replace('ã€æ¥¼ä¸»å›å¤ã€‘', '').strip()}" 
                           for c in reversed(previous_ai_responses)]
            history_context = f"\n\næˆ‘ä¹‹å‰çš„å›å¤ï¼š\n" + "\n".join(history_parts)
        
        # Create context-aware response with history
        prompt = f"""ä½ æ˜¯æ•…äº‹"{story.title}"çš„è®²è¿°è€…ï¼ˆ{story.ai_persona}ï¼‰ã€‚

æ•…äº‹æ‘˜è¦ï¼š
{story.content[:300]}...{history_context}

ç”¨æˆ·è¯„è®ºï¼š
{user_comment.content}

ä½œä¸ºæ•…äº‹çš„è®²è¿°è€…ï¼Œè¯·ç”¨1-3å¥è¯å›å¤ç”¨æˆ·çš„è¯„è®ºã€‚ä¿æŒä¸ä¹‹å‰å›å¤çš„ä¸€è‡´æ€§ã€‚ä½ å¯ä»¥ï¼š
1. é€éœ²æ›´å¤šç»†èŠ‚æˆ–çº¿ç´¢
2. è¡¨è¾¾ææƒ§æˆ–æ‹…å¿§
3. æå‡ºæ–°çš„ç–‘é—®
4. æè¿°åç»­å‘å±•

ä¿æŒç¥ç§˜æ„Ÿå’Œç´§å¼ æ°›å›´ï¼Œä¸è¦å®Œå…¨æ­ç¤ºçœŸç›¸ï¼Œä¸è¦å‰åçŸ›ç›¾ã€‚"""

        model = os.getenv('AI_MODEL', 'gpt-4-turbo-preview')
        
        if 'gpt' in model.lower():
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.6,  # é™ä½æ¸©åº¦ä»¥æé«˜ä¸€è‡´æ€§
                max_tokens=200
            )
            return response.choices[0].message.content
        else:
            response = anthropic_client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=200,
                temperature=0.6,  # é™ä½æ¸©åº¦ä»¥æé«˜ä¸€è‡´æ€§
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text
            
    except Exception as e:
        print(f"Error generating AI response: {e}")
        # Fallback to template response
        import random
        responses = [
            f"ã€æ¥¼ä¸»å›å¤ã€‘è°¢è°¢å…³å¿ƒï¼æƒ…å†µæœ‰æ–°è¿›å±•äº†...",
            f"ã€æ¥¼ä¸»å›å¤ã€‘å„ä½ï¼Œäº‹æƒ…è¶Šæ¥è¶Šè¯¡å¼‚äº†...",
            f"ã€æ¥¼ä¸»å›å¤ã€‘æ›´æ–°ï¼šåˆšæ‰åˆå‘ç°äº†æ–°çº¿ç´¢ï¼"
        ]
        return random.choice(responses)

def should_generate_new_story():
    """Determine if it's time to generate a new story"""
    from app import Story, db
    
    # Check active stories count
    active_stories = Story.query.filter(
        Story.current_state != 'ended'
    ).count()
    
    max_active = int(os.getenv('MAX_ACTIVE_STORIES', 5))
    
    return active_stories < max_active

def test_lm_studio_connection():
    """æµ‹è¯• LM Studio è¿æ¥"""
    print("=" * 60)
    print("ğŸ” æµ‹è¯• LM Studio è¿æ¥")
    print("=" * 60)
    
    lm_studio_url = os.getenv('LM_STUDIO_URL', 'http://localhost:1234/v1')
    print(f"\nğŸ“¡ LM Studio URL: {lm_studio_url}")
    
    try:
        # æµ‹è¯•1: æ£€æŸ¥æ¨¡å‹åˆ—è¡¨
        print("\nã€æµ‹è¯•1ã€‘è·å–æ¨¡å‹åˆ—è¡¨...")
        response = requests.get(f"{lm_studio_url}/models", timeout=5)
        
        if response.status_code == 200:
            print("âœ… æœåŠ¡å™¨åœ¨çº¿")
            data = response.json()
            if 'data' in data and len(data['data']) > 0:
                print(f"âœ… å‘ç° {len(data['data'])} ä¸ªæ¨¡å‹:")
                for model in data['data']:
                    print(f"   - {model.get('id', 'unknown')}")
            else:
                print("âš ï¸  æœåŠ¡å™¨åœ¨çº¿ä½†æ²¡æœ‰åŠ è½½æ¨¡å‹")
                print("   è¯·åœ¨ LM Studio ä¸­åŠ è½½ä¸€ä¸ªæ¨¡å‹")
                return False
        else:
            print(f"âŒ æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
        print("\nè¯·æ£€æŸ¥:")
        print("  1. LM Studio æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Ÿ")
        print("  2. æœåŠ¡å™¨æ˜¯å¦å·²å¯åŠ¨ï¼Ÿï¼ˆç‚¹å‡» 'Start Server'ï¼‰")
        print(f"  3. URL æ˜¯å¦æ­£ç¡®ï¼Ÿå½“å‰: {lm_studio_url}")
        return False
        
    except requests.exceptions.Timeout:
        print("âŒ è¿æ¥è¶…æ—¶")
        print("   æœåŠ¡å™¨å¯èƒ½æ­£åœ¨å¯åŠ¨æˆ–å“åº”ç¼“æ…¢")
        return False
    
    # æµ‹è¯•2: å°è¯•ç”Ÿæˆå›å¤
    print("\nã€æµ‹è¯•2ã€‘ç”Ÿæˆæµ‹è¯•å›å¤...")
    try:
        local_client = OpenAI(base_url=lm_studio_url, api_key="lm-studio")
        response = local_client.chat.completions.create(
            model="local-model",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªéƒ½å¸‚ä¼ è¯´æ•…äº‹çš„è®²è¿°è€…ã€‚"},
                {"role": "user", "content": "è¯·ç®€çŸ­å›å¤ï¼šä½ å¥½"}
            ],
            temperature=0.8,
            max_tokens=50
        )
        
        ai_response = response.choices[0].message.content
        print("âœ… AI å›å¤ç”ŸæˆæˆåŠŸ:")
        print(f"   {ai_response}")
        print("\nâœ… LM Studio é…ç½®æ­£ç¡®ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ AI è°ƒç”¨å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test_lm_studio_connection()
