#!/usr/bin/env python3
"""
è°ƒè¯•è„šæœ¬ï¼šæµ‹è¯•éŸ³é¢‘ç”Ÿæˆå’ŒLM Studioè¿æ¥
"""
import os
import sys

print("=" * 60)
print("ğŸ” è¯Šæ–­æµ‹è¯•å¼€å§‹")
print("=" * 60)

# æµ‹è¯•1: æ£€æŸ¥éŸ³é¢‘ç”Ÿæˆä¾èµ–
print("\nã€æµ‹è¯•1ã€‘æ£€æŸ¥éŸ³é¢‘ç”Ÿæˆä¾èµ–")
print("-" * 60)

try:
    import numpy as np
    print("âœ… numpy å·²å®‰è£…:", np.__version__)
except ImportError as e:
    print("âŒ numpy æœªå®‰è£…:", e)

try:
    from scipy.io import wavfile
    from scipy import signal
    print("âœ… scipy å·²å®‰è£…")
except ImportError as e:
    print("âŒ scipy æœªå®‰è£…:", e)

try:
    from pydub import AudioSegment
    from pydub.generators import Sine
    print("âœ… pydub å·²å®‰è£…")
except ImportError as e:
    print("âš ï¸  pydub æœªå®‰è£…ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰:", e)

# æµ‹è¯•2: å°è¯•ç”ŸæˆéŸ³é¢‘
print("\nã€æµ‹è¯•2ã€‘å°è¯•ç”ŸæˆéŸ³é¢‘æ–‡ä»¶")
print("-" * 60)

try:
    from ai_engine import generate_evidence_audio
    
    print("ğŸ“ è°ƒç”¨ generate_evidence_audio('æµ‹è¯•éŸ³é¢‘ç”Ÿæˆ')...")
    audio_path = generate_evidence_audio("æµ‹è¯•éŸ³é¢‘ç”Ÿæˆ - é¦™æ¸¯éƒ½å¸‚ä¼ è¯´")
    
    if audio_path:
        print(f"âœ… å‡½æ•°è¿”å›è·¯å¾„: {audio_path}")
        
        # æ£€æŸ¥å®é™…æ–‡ä»¶
        full_path = f"static{audio_path}" if audio_path.startswith('/') else audio_path
        if os.path.exists(full_path):
            file_size = os.path.getsize(full_path)
            print(f"âœ… æ–‡ä»¶å·²åˆ›å»º: {full_path}")
            print(f"   æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚ ({file_size/1024:.1f} KB)")
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
    else:
        print("âŒ å‡½æ•°è¿”å› None")
        
except Exception as e:
    print(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# æµ‹è¯•3: æ£€æŸ¥ LM Studio è¿æ¥
print("\nã€æµ‹è¯•3ã€‘æ£€æŸ¥ LM Studio è¿æ¥")
print("-" * 60)

try:
    from dotenv import load_dotenv
    load_dotenv()
    
    lm_studio_url = os.getenv('LM_STUDIO_URL', 'http://localhost:1234/v1')
    print(f"ğŸ“¡ LM Studio URL: {lm_studio_url}")
    
    # å°è¯•è¿æ¥
    import requests
    print(f"   å°è¯•è¿æ¥åˆ° {lm_studio_url}/models ...")
    
    try:
        response = requests.get(
            f"{lm_studio_url}/models",
            timeout=5
        )
        print(f"   å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            print("âœ… LM Studio æœåŠ¡å™¨åœ¨çº¿")
            data = response.json()
            if 'data' in data and len(data['data']) > 0:
                print(f"   å¯ç”¨æ¨¡å‹æ•°é‡: {len(data['data'])}")
                for model in data['data'][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"   - {model.get('id', 'unknown')}")
            else:
                print("âš ï¸  æ²¡æœ‰åŠ è½½çš„æ¨¡å‹")
        else:
            print(f"âš ï¸  æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ° LM Studio æœåŠ¡å™¨")
        print(f"   è¯·ç¡®è®¤:")
        print(f"   1. LM Studio æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Ÿ")
        print(f"   2. URL æ˜¯å¦æ­£ç¡®ï¼Ÿå½“å‰: {lm_studio_url}")
        print(f"   3. å¦‚æœæ˜¯è¿œç¨‹æœåŠ¡å™¨ (192.168.x.x)ï¼Œç½‘ç»œæ˜¯å¦è¿é€šï¼Ÿ")
        
    except requests.exceptions.Timeout:
        print("âŒ è¿æ¥è¶…æ—¶")
        print(f"   LM Studio å¯èƒ½æ­£åœ¨å¯åŠ¨æˆ–å“åº”ç¼“æ…¢")
        
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
    print("   éœ€è¦å®‰è£…: pip install requests python-dotenv")

# æµ‹è¯•4: æµ‹è¯• AI å“åº”ç”Ÿæˆ
print("\nã€æµ‹è¯•4ã€‘æµ‹è¯• AI å“åº”ç”Ÿæˆ")
print("-" * 60)

try:
    from ai_engine import generate_ai_response
    from models import Story, Comment, User
    from app import app, db
    
    with app.app_context():
        # è·å–ç¬¬ä¸€ä¸ªæ•…äº‹å’Œè¯„è®ºè¿›è¡Œæµ‹è¯•
        story = Story.query.first()
        comment = Comment.query.first()
        
        if story and comment:
            print(f"ğŸ“– æµ‹è¯•æ•…äº‹: {story.title}")
            print(f"ğŸ’¬ æµ‹è¯•è¯„è®º: {comment.content[:50]}...")
            print(f"ğŸ¤– è°ƒç”¨ generate_ai_response()...")
            
            response = generate_ai_response(story, comment)
            
            print(f"\nç”Ÿæˆçš„å›å¤:")
            print("-" * 60)
            print(response)
            print("-" * 60)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡æ¿å›å¤
            if "ã€æ¥¼ä¸»å›å¤ã€‘" in response and ("åˆšå»ç°åœºæ‹äº†ç…§" in response or "è°¢è°¢" in response):
                print("âš ï¸  è¿™æ˜¯æ¨¡æ¿å›å¤ï¼ˆfallbackï¼‰ï¼Œä¸æ˜¯ LM Studio ç”Ÿæˆçš„")
                print("   åŸå› : LM Studio è¿æ¥å¤±è´¥æˆ–æœªé…ç½®")
            else:
                print("âœ… è¿™çœ‹èµ·æ¥æ˜¯ AI ç”Ÿæˆçš„å›å¤")
        else:
            print("âš ï¸  æ•°æ®åº“ä¸­æ²¡æœ‰æ•…äº‹æˆ–è¯„è®ºï¼Œæ— æ³•æµ‹è¯•")
            
except Exception as e:
    print(f"âŒ AI å“åº”æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# æ€»ç»“
print("\n" + "=" * 60)
print("ğŸ“Š è¯Šæ–­æ€»ç»“")
print("=" * 60)

print("""
è¯·æ ¹æ®ä¸Šé¢çš„æµ‹è¯•ç»“æœè¿›è¡Œä¿®å¤:

ã€éŸ³é¢‘é—®é¢˜ã€‘
- å¦‚æœ scipy æœªå®‰è£…: pip install scipy numpy
- å¦‚æœæ–‡ä»¶æœªåˆ›å»ºä½†æ— é”™è¯¯: æ£€æŸ¥ static/generated/ ç›®å½•æƒé™
- å¦‚æœæœ‰å¼‚å¸¸: æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯

ã€LM Studio é—®é¢˜ã€‘
- å¦‚æœè¿æ¥å¤±è´¥:
  1. å¯åŠ¨ LM Studio åº”ç”¨
  2. åœ¨ LM Studio ä¸­åŠ è½½ä¸€ä¸ªæ¨¡å‹ï¼ˆæ¨è Qwen æˆ– Llamaï¼‰
  3. ç¡®ä¿ "Start Server" å·²å¼€å¯
  4. æ£€æŸ¥ç«¯å£æ˜¯å¦æ˜¯ 1234
  5. å¦‚æœæ˜¯è¿œç¨‹æœåŠ¡å™¨ï¼Œæ£€æŸ¥é˜²ç«å¢™å’Œç½‘ç»œ

- ä¿®æ”¹é…ç½®:
  ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®:
  LM_STUDIO_URL=http://localhost:1234/v1  # æœ¬åœ°
  # æˆ–
  LM_STUDIO_URL=http://192.168.10.145:1234/v1  # è¿œç¨‹

- æµ‹è¯•è¿æ¥:
  curl http://localhost:1234/v1/models
  # åº”è¯¥è¿”å›å·²åŠ è½½çš„æ¨¡å‹åˆ—è¡¨
""")

print("=" * 60)
print("ğŸ è¯Šæ–­æµ‹è¯•å®Œæˆ")
print("=" * 60)
